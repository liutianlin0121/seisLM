{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seisLM.evaluation import pick_eval\n",
    "from seisLM.utils import project_path\n",
    "from phasepick_model_registry import ckpt_registry\n",
    "from seisLM.model.task_specific.phasepick_models import EQTransformerLit\n",
    "from seisLM.model.task_specific.phasepick_models import GPDLit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scicore/home/dokman0000/liu0003/anaconda3/envs/seisbench/lib/python3.9/site-packages/lightning/pytorch/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.4.0, which is newer than your current Lightning version: v2.2.5\n",
      "2024-08-21 15:03:23,274 | seisbench | WARNING | Check available storage and memory before downloading and general use of ETHZ dataset. Dataset size: waveforms.hdf5 ~22Gb, metadata.csv ~13Mb\n",
      "WARNING:seisbench:Check available storage and memory before downloading and general use of ETHZ dataset. Dataset size: waveforms.hdf5 ~22Gb, metadata.csv ~13Mb\n",
      "WARNING:root:Starting set test\n",
      "Preloading waveforms: 100%|██████████| 10485/10485 [01:06<00:00, 157.49it/s]\n",
      "WARNING:root:Starting task 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d4aac204ee4d0ca25cf0486b1bc850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Saving predictions to /scicore/home/dokman0000/liu0003/projects/seisLM/results/evaluation/ethz_eqtransformer_ETHZ_train_frac_1.0_model_EQTransformer_seed_42_time_2024-08-19-09h-40m-33s_ETHZ/test_task1.csv\n",
      "WARNING:root:Starting task 23\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37de7e3014af4f77b43f2d71a410f256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Saving predictions to /scicore/home/dokman0000/liu0003/projects/seisLM/results/evaluation/ethz_eqtransformer_ETHZ_train_frac_1.0_model_EQTransformer_seed_42_time_2024-08-19-09h-40m-33s_ETHZ/test_task23.csv\n",
      "/scicore/home/dokman0000/liu0003/anaconda3/envs/seisbench/lib/python3.9/site-packages/lightning/pytorch/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.4.0, which is newer than your current Lightning version: v2.2.5\n",
      "2024-08-21 15:05:41,463 | seisbench | WARNING | Check available storage and memory before downloading and general use of ETHZ dataset. Dataset size: waveforms.hdf5 ~22Gb, metadata.csv ~13Mb\n",
      "WARNING:seisbench:Check available storage and memory before downloading and general use of ETHZ dataset. Dataset size: waveforms.hdf5 ~22Gb, metadata.csv ~13Mb\n",
      "WARNING:root:Starting set test\n",
      "Preloading waveforms: 100%|██████████| 10485/10485 [01:05<00:00, 160.06it/s]\n",
      "WARNING:root:Starting task 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35ebfee81714f93ac05faf81cc2ec4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Saving predictions to /scicore/home/dokman0000/liu0003/projects/seisLM/results/evaluation/ethz_eqtransformer_ETHZ_train_frac_0.5_model_EQTransformer_seed_42_time_2024-08-19-09h-25m-43s_ETHZ/test_task1.csv\n",
      "WARNING:root:Starting task 23\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387bdd22863f4bdf8d41b3df187b9ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Saving predictions to /scicore/home/dokman0000/liu0003/projects/seisLM/results/evaluation/ethz_eqtransformer_ETHZ_train_frac_0.5_model_EQTransformer_seed_42_time_2024-08-19-09h-25m-43s_ETHZ/test_task23.csv\n"
     ]
    }
   ],
   "source": [
    "data_name = 'ETHZ'\n",
    "batch_size = 64\n",
    "sets = 'test'\n",
    "\n",
    "for train_frac in ['1.0', '0.5']:\n",
    "  ckpt_paths = ckpt_registry[data_name]['EQTransformer']\n",
    "  ckpt_path = ckpt_paths[train_frac]\n",
    "  model = EQTransformerLit.load_from_checkpoint(\n",
    "    project_path.gitdir() + '/' + ckpt_path\n",
    "  )\n",
    "  target_path = project_path.gitdir() + f'/data/targets/{data_name}/'\n",
    "  save_tag = ckpt_path.split('/')[-3]\n",
    "\n",
    "  pick_eval.save_pick_predictions(\n",
    "    model=model,\n",
    "    target_path=target_path,\n",
    "    sets=sets,\n",
    "    save_tag=save_tag,\n",
    "    batch_size=batch_size\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # pred_path = '/scicore/home/dokman0000/liu0003/projects/seisLM/results/evaluation/geofon_eqtransformer_GEOFON_train_frac_0.05_model_EQTransformer_seed_42_time_2024-08-16-22h-58m-10s_GEOFON/test_task23.csv'\n",
    "# pred_path = '/scicore/home/dokman0000/liu0003/projects/seisLM/results/evaluation/geofon_eqtransformer_GEOFON_train_frac_0.05_model_EQTransformer_seed_42_time_2024-08-16-22h-58m-10s_GEOFON/test_task23.csv'\n",
    "# pred = pd.read_csv(pred_path)\n",
    "# pred[\"phase_label_bin\"] = pred[\"phase_label\"] == \"P\"\n",
    "# pred[\"score_p_or_s\"]# = pred[\"score_p_or_s\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import torch\n",
    "# import logging\n",
    "# from seisLM.evaluation.pick_eval import get_dataset_by_name\n",
    "\n",
    "# targets = Path(target_path)\n",
    "# # sets = sets.split(\",\")\n",
    "# model.eval()\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# dataset = get_dataset_by_name(targets.name)(\n",
    "#     sampling_rate=100, component_order=\"ZNE\", dimension_order=\"NCW\",\n",
    "#     cache=\"full\"\n",
    "# )\n",
    "\n",
    "# eval_set = 'test'\n",
    "# # for eval_set in sets:\n",
    "# split = dataset.get_split(eval_set)\n",
    "# logging.warning(f\"Starting set {eval_set}\")\n",
    "# split.preload_waveforms(pbar=True)\n",
    "# task = \"23\"\n",
    "# task_csv = targets / f\"task{task}.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# import lightning as L\n",
    "# import seisbench.generate as sbg\n",
    "# num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "      # task_targets = pd.read_csv(task_csv)\n",
    "      # task_targets = task_targets[task_targets[\"trace_split\"] == eval_set]\n",
    "\n",
    "      # generator = sbg.SteeredGenerator(split, task_targets)\n",
    "      # generator.add_augmentations(model.get_eval_augmentations())\n",
    "\n",
    "      # loader = DataLoader(\n",
    "      #   generator, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "      # )\n",
    "      # trainer = L.Trainer(\n",
    "      #   accelerator=\"gpu\",\n",
    "      #   devices=1,\n",
    "      #   logger=False,            # Disable the default logger\n",
    "      #   enable_checkpointing=False  # Disable automatic checkpointing\n",
    "      # )\n",
    "\n",
    "      # predictions = trainer.predict(model, loader)\n",
    "\n",
    "      # # Merge batches\n",
    "      # merged_predictions = []\n",
    "\n",
    "      # for i, _ in enumerate(predictions[0]):\n",
    "      #   merged_predictions.append(torch.cat([x[i] for x in predictions]))\n",
    "\n",
    "      # merged_predictions = [x.cpu().numpy() for x in merged_predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter_loader)\n",
    "\n",
    "# with torch.no_grad():\n",
    "\n",
    "#     x = batch[\"X\"]\n",
    "#     window_borders = batch[\"window_borders\"]\n",
    "\n",
    "#     det_pred, p_pred, s_pred = model(x)\n",
    "\n",
    "#     score_detection = torch.zeros(det_pred.shape[0])\n",
    "#     score_p_or_s = torch.zeros(det_pred.shape[0])\n",
    "#     p_sample = torch.zeros(det_pred.shape[0], dtype=int)\n",
    "#     s_sample = torch.zeros(det_pred.shape[0], dtype=int)\n",
    "\n",
    "#     for i in range(det_pred.shape[0]):\n",
    "#       start_sample, end_sample = window_borders[i]\n",
    "#       local_det_pred = det_pred[i, start_sample:end_sample]\n",
    "#       local_p_pred = p_pred[i, start_sample:end_sample]\n",
    "#       local_s_pred = s_pred[i, start_sample:end_sample]\n",
    "\n",
    "#       score_detection[i] = torch.max(local_det_pred)\n",
    "#       score_p_or_s[i] = torch.max(local_p_pred) / (torch.max(\n",
    "#           local_s_pred\n",
    "#       ) + 1e-10)  # most likely P by most likely S\n",
    "\n",
    "#       p_sample[i] = torch.argmax(local_p_pred)\n",
    "#       s_sample[i] = torch.argmax(local_s_pred)\n",
    "\n",
    "# p_true = batch[\"y\"][:, 0]\n",
    "# s_true = batch[\"y\"][:, 1]\n",
    "\n",
    "\n",
    "# plt.plot(p_pred[0].cpu().numpy())\n",
    "# plt.plot(s_pred[0].cpu().numpy())\n",
    "# plt.plot(p_true[0].cpu().numpy())\n",
    "# plt.plot(s_true[0].cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seisbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
