{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/scicore/home/dokman0000/liu0003/anaconda3/envs/seisbench/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
      "name: weight, mean -0.0010924262460321188, std 0.18174836039543152\n",
      "name: bias, mean 0.013098427094519138, std 0.18609926104545593\n",
      "--------\n",
      "LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Wav2Vec2LayerNormConvLayer(\n",
      "  (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
      "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "name: conv.weight, mean -0.0025054551661014557, std 0.4455367922782898\n",
      "name: conv.bias, mean -0.0032587391324341297, std 0.18554647266864777\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "name: weight, mean -9.818029866437428e-06, std 0.014730403199791908\n",
      "name: bias, mean 0.0015462866285815835, std 0.015121903270483017\n",
      "--------\n",
      "LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Wav2Vec2LayerNormConvLayer(\n",
      "  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "name: conv.weight, mean -5.046659498475492e-05, std 0.036100123077631\n",
      "name: conv.bias, mean 0.0009091057581827044, std 0.014743977226316929\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "name: weight, mean -2.381625927228015e-05, std 0.01472777221351862\n",
      "name: bias, mean 0.00021190302504692227, std 0.014244990423321724\n",
      "--------\n",
      "LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Wav2Vec2LayerNormConvLayer(\n",
      "  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "name: conv.weight, mean 2.352310985997974e-07, std 0.03607241064310074\n",
      "name: conv.bias, mean -0.0010985223343595862, std 0.015055416151881218\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "name: weight, mean -1.7659856894169934e-05, std 0.014729737304151058\n",
      "name: bias, mean -0.00020582845900207758, std 0.014688527211546898\n",
      "--------\n",
      "LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Wav2Vec2LayerNormConvLayer(\n",
      "  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "name: conv.weight, mean -1.0806208592839539e-05, std 0.036102764308452606\n",
      "name: conv.bias, mean 0.0004939131904393435, std 0.015146415680646896\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "name: weight, mean 9.248746209777892e-06, std 0.014724543318152428\n",
      "name: bias, mean 0.0001155372301582247, std 0.014958398416638374\n",
      "--------\n",
      "LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Wav2Vec2LayerNormConvLayer(\n",
      "  (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "name: conv.weight, mean 4.364449341665022e-05, std 0.03609722480177879\n",
      "name: conv.bias, mean -8.567776239942759e-05, std 0.014661132358014584\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
      "name: weight, mean -3.689054210553877e-06, std 0.018044350668787956\n",
      "name: bias, mean 0.0003283615515101701, std 0.017780423164367676\n",
      "--------\n",
      "LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Wav2Vec2LayerNormConvLayer(\n",
      "  (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
      "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "name: conv.weight, mean 2.196892091888003e-05, std 0.04419323801994324\n",
      "name: conv.bias, mean -0.0007734612445347011, std 0.0177419725805521\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
      "name: weight, mean 3.508639565552585e-07, std 0.0180242657661438\n",
      "name: bias, mean 0.0007773078978061676, std 0.01771017536520958\n",
      "--------\n",
      "LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Wav2Vec2LayerNormConvLayer(\n",
      "  (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
      "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "name: conv.weight, mean -3.9847378502599895e-05, std 0.044176314026117325\n",
      "name: conv.bias, mean -0.0019032731652259827, std 0.017737187445163727\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "ModuleList(\n",
      "  (0): Wav2Vec2LayerNormConvLayer(\n",
      "    (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (activation): GELUActivation()\n",
      "  )\n",
      "  (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n",
      "    (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (activation): GELUActivation()\n",
      "  )\n",
      "  (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n",
      "    (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (activation): GELUActivation()\n",
      "  )\n",
      ")\n",
      "name: 0.conv.weight, mean -0.0025054551661014557, std 0.4455367922782898\n",
      "name: 0.conv.bias, mean -0.0032587391324341297, std 0.18554647266864777\n",
      "name: 0.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 0.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 1.conv.weight, mean -5.046659498475492e-05, std 0.036100123077631\n",
      "name: 1.conv.bias, mean 0.0009091057581827044, std 0.014743977226316929\n",
      "name: 1.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 1.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 2.conv.weight, mean 2.352310985997974e-07, std 0.03607241064310074\n",
      "name: 2.conv.bias, mean -0.0010985223343595862, std 0.015055416151881218\n",
      "name: 2.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 2.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 3.conv.weight, mean -1.0806208592839539e-05, std 0.036102764308452606\n",
      "name: 3.conv.bias, mean 0.0004939131904393435, std 0.015146415680646896\n",
      "name: 3.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 3.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 4.conv.weight, mean 4.364449341665022e-05, std 0.03609722480177879\n",
      "name: 4.conv.bias, mean -8.567776239942759e-05, std 0.014661132358014584\n",
      "name: 4.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 4.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 5.conv.weight, mean 2.196892091888003e-05, std 0.04419323801994324\n",
      "name: 5.conv.bias, mean -0.0007734612445347011, std 0.0177419725805521\n",
      "name: 5.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 5.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 6.conv.weight, mean -3.9847378502599895e-05, std 0.044176314026117325\n",
      "name: 6.conv.bias, mean -0.0019032731652259827, std 0.017737187445163727\n",
      "name: 6.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 6.layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2FeatureEncoder(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): Wav2Vec2LayerNormConvLayer(\n",
      "      (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n",
      "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n",
      "      (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "name: conv_layers.0.conv.weight, mean -0.0025054551661014557, std 0.4455367922782898\n",
      "name: conv_layers.0.conv.bias, mean -0.0032587391324341297, std 0.18554647266864777\n",
      "name: conv_layers.0.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: conv_layers.0.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: conv_layers.1.conv.weight, mean -5.046659498475492e-05, std 0.036100123077631\n",
      "name: conv_layers.1.conv.bias, mean 0.0009091057581827044, std 0.014743977226316929\n",
      "name: conv_layers.1.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: conv_layers.1.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: conv_layers.2.conv.weight, mean 2.352310985997974e-07, std 0.03607241064310074\n",
      "name: conv_layers.2.conv.bias, mean -0.0010985223343595862, std 0.015055416151881218\n",
      "name: conv_layers.2.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: conv_layers.2.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: conv_layers.3.conv.weight, mean -1.0806208592839539e-05, std 0.036102764308452606\n",
      "name: conv_layers.3.conv.bias, mean 0.0004939131904393435, std 0.015146415680646896\n",
      "name: conv_layers.3.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: conv_layers.3.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: conv_layers.4.conv.weight, mean 4.364449341665022e-05, std 0.03609722480177879\n",
      "name: conv_layers.4.conv.bias, mean -8.567776239942759e-05, std 0.014661132358014584\n",
      "name: conv_layers.4.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: conv_layers.4.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: conv_layers.5.conv.weight, mean 2.196892091888003e-05, std 0.04419323801994324\n",
      "name: conv_layers.5.conv.bias, mean -0.0007734612445347011, std 0.0177419725805521\n",
      "name: conv_layers.5.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: conv_layers.5.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: conv_layers.6.conv.weight, mean -3.9847378502599895e-05, std 0.044176314026117325\n",
      "name: conv_layers.6.conv.bias, mean -0.0019032731652259827, std 0.017737187445163727\n",
      "name: conv_layers.6.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: conv_layers.6.layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=512, out_features=768, bias=True)\n",
      "name: weight, mean -3.842786099994555e-05, std 0.025521205738186836\n",
      "name: bias, mean -0.000579161336645484, std 0.02618573233485222\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeatureProjection(\n",
      "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: projection.weight, mean -3.1230472814058885e-05, std 0.01997668668627739\n",
      "name: projection.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "_WeightNorm()\n",
      "--------\n",
      "ParametrizationList(\n",
      "  (0): _WeightNorm()\n",
      ")\n",
      "name: original0, mean 1.4145300388336182, std 0.0034867976792156696\n",
      "name: original1, mean -2.3635434445168357e-06, std 0.007367375306785107\n",
      "--------\n",
      "ModuleDict(\n",
      "  (weight): ParametrizationList(\n",
      "    (0): _WeightNorm()\n",
      "  )\n",
      ")\n",
      "name: weight.original0, mean 1.4145300388336182, std 0.0034867976792156696\n",
      "name: weight.original1, mean -2.3635434445168357e-06, std 0.007367375306785107\n",
      "--------\n",
      "ParametrizedConv1d(\n",
      "  768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "  (parametrizations): ModuleDict(\n",
      "    (weight): ParametrizationList(\n",
      "      (0): _WeightNorm()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "name: bias, mean -0.0002882481785491109, std 0.00733975088223815\n",
      "name: parametrizations.weight.original0, mean 1.4145300388336182, std 0.0034867976792156696\n",
      "name: parametrizations.weight.original1, mean -2.3635434445168357e-06, std 0.007367375306785107\n",
      "--------\n",
      "Wav2Vec2SamePadLayer()\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Wav2Vec2PositionalConvEmbedding(\n",
      "  (conv): ParametrizedConv1d(\n",
      "    768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "    (parametrizations): ModuleDict(\n",
      "      (weight): ParametrizationList(\n",
      "        (0): _WeightNorm()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (padding): Wav2Vec2SamePadLayer()\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "name: conv.bias, mean -1.533203430881258e-05, std 0.007319378200918436\n",
      "name: conv.parametrizations.weight.original0, mean 1.4145300388336182, std 0.0034867976792156696\n",
      "name: conv.parametrizations.weight.original1, mean -2.3635434445168357e-06, std 0.007367375306785107\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 3.5980894608655944e-05, std 0.020834481343626976\n",
      "name: bias, mean 0.0004579030501190573, std 0.02107885479927063\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -2.4302898964378983e-05, std 0.020835738629102707\n",
      "name: bias, mean 0.0010482434881851077, std 0.02061266452074051\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 4.517418346949853e-05, std 0.02082228474318981\n",
      "name: bias, mean 0.001014587003737688, std 0.02052575722336769\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.1385973266442306e-05, std 0.0208237674087286\n",
      "name: bias, mean -0.0005313207511790097, std 0.020436648279428482\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean 1.0291325452271849e-05, std 0.019992340356111526\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean -2.940171179943718e-05, std 0.01997837796807289\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean 2.2064874428906478e-05, std 0.020014507696032524\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean 2.773741698547383e-06, std 0.019974686205387115\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean 1.1964257282670587e-06, std 0.020823663100600243\n",
      "name: bias, mean -0.00038473564200103283, std 0.020767899230122566\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean -2.0311354091973044e-06, std 0.010414374060928822\n",
      "name: bias, mean -0.0002319168852409348, std 0.010229019448161125\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean 2.045001383521594e-05, std 0.020001910626888275\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean -6.6482816691859625e-06, std 0.020012028515338898\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean 1.0291325452271849e-05, std 0.019992340356111526\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean -2.940171179943718e-05, std 0.01997837796807289\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean 2.2064874428906478e-05, std 0.020014507696032524\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean 2.773741698547383e-06, std 0.019974686205387115\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean 2.045001383521594e-05, std 0.020001910626888275\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean -6.6482816691859625e-06, std 0.020012028515338898\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -1.9578459614422172e-05, std 0.020837528631091118\n",
      "name: bias, mean 0.0008779774070717394, std 0.02111109159886837\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -1.529745895822998e-05, std 0.02083943597972393\n",
      "name: bias, mean 9.264112304663286e-05, std 0.020022118464112282\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -4.7474797611357644e-05, std 0.020815301686525345\n",
      "name: bias, mean -0.0009237062186002731, std 0.02072775736451149\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.2482162674132269e-05, std 0.02085852064192295\n",
      "name: bias, mean -0.0004060077480971813, std 0.020744096487760544\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean -3.5533259506337345e-05, std 0.020023051649332047\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean -3.307362203486264e-05, std 0.020003318786621094\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean 1.3059252523817122e-05, std 0.020004164427518845\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean 2.397509706497658e-05, std 0.019984198734164238\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean -7.423109764204128e-06, std 0.020833829417824745\n",
      "name: bias, mean 0.00015417981194332242, std 0.020597022026777267\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean 3.7595398794110224e-07, std 0.010412153787910938\n",
      "name: bias, mean -0.00032908018329180777, std 0.010332323610782623\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean 3.714662625498022e-06, std 0.02000550739467144\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean 2.4925735488068312e-05, std 0.02000564895570278\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean -3.5533259506337345e-05, std 0.020023051649332047\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean -3.307362203486264e-05, std 0.020003318786621094\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean 1.3059252523817122e-05, std 0.020004164427518845\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean 2.397509706497658e-05, std 0.019984198734164238\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean 3.714662625498022e-06, std 0.02000550739467144\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean 2.4925735488068312e-05, std 0.02000564895570278\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.683632581261918e-05, std 0.020833870396018028\n",
      "name: bias, mean -2.2215584976947866e-05, std 0.02087295986711979\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.617761517991312e-05, std 0.02081448584794998\n",
      "name: bias, mean 1.3208365999162197e-05, std 0.02070852927863598\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 4.114998591830954e-05, std 0.02082628756761551\n",
      "name: bias, mean -0.00015740295930299908, std 0.021003564819693565\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -6.2212589000409935e-06, std 0.02081921324133873\n",
      "name: bias, mean -0.00017589442722965032, std 0.021135792136192322\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean -1.0827562618942466e-05, std 0.019993958994746208\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean 3.789313495872193e-06, std 0.019967161118984222\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean 4.3217369238846004e-05, std 0.019983502104878426\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean -3.928915612050332e-05, std 0.019979378208518028\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean -4.745554178953171e-06, std 0.02083253487944603\n",
      "name: bias, mean -0.00042999806464649737, std 0.020934036001563072\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean -1.21332811886532e-06, std 0.010416406206786633\n",
      "name: bias, mean -0.00046619694330729544, std 0.010314489714801311\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean -2.6740803150460124e-05, std 0.019988693296909332\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean 8.920041182136629e-06, std 0.02000530995428562\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean -1.0827562618942466e-05, std 0.019993958994746208\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean 3.789313495872193e-06, std 0.019967161118984222\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean 4.3217369238846004e-05, std 0.019983502104878426\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean -3.928915612050332e-05, std 0.019979378208518028\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean -2.6740803150460124e-05, std 0.019988693296909332\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean 8.920041182136629e-06, std 0.02000530995428562\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -2.4500868676113896e-06, std 0.020838137716054916\n",
      "name: bias, mean -0.0002180354349547997, std 0.020982904359698296\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -4.5830674935132265e-06, std 0.020856447517871857\n",
      "name: bias, mean 8.810475264908746e-05, std 0.02088933065533638\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -3.564069265848957e-05, std 0.020827749744057655\n",
      "name: bias, mean -4.287257979740389e-05, std 0.020413627848029137\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 2.139634671038948e-05, std 0.020817367359995842\n",
      "name: bias, mean 0.0003233115130569786, std 0.020695339888334274\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean 2.0223720639478415e-05, std 0.02001813054084778\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean 2.672090158739593e-05, std 0.019983235746622086\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean 1.2204828635731246e-05, std 0.019986022263765335\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean 3.982783164246939e-05, std 0.020009377971291542\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean -2.2705285118718166e-06, std 0.02082868665456772\n",
      "name: bias, mean -8.418907964369282e-05, std 0.020913923159241676\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean -3.6325961900729453e-06, std 0.010416246950626373\n",
      "name: bias, mean -9.624426456866786e-05, std 0.010393137112259865\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean -2.051756837317953e-06, std 0.020013613626360893\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean -1.8938973880722187e-05, std 0.019999446347355843\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean 2.0223720639478415e-05, std 0.02001813054084778\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean 2.672090158739593e-05, std 0.019983235746622086\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean 1.2204828635731246e-05, std 0.019986022263765335\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean 3.982783164246939e-05, std 0.020009377971291542\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean -2.051756837317953e-06, std 0.020013613626360893\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean -1.8938973880722187e-05, std 0.019999446347355843\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -3.777566007556743e-06, std 0.020846296101808548\n",
      "name: bias, mean 0.0012164115905761719, std 0.0209095049649477\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -1.2696168596448842e-06, std 0.020835045725107193\n",
      "name: bias, mean 0.0001363671472063288, std 0.020469186827540398\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.0842209121619817e-05, std 0.020834194496273994\n",
      "name: bias, mean -0.0005274283466860652, std 0.020494110882282257\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -2.002299424930243e-06, std 0.020842600613832474\n",
      "name: bias, mean -0.00021964444022160023, std 0.020938660949468613\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean 4.6523713535862043e-05, std 0.020009001716971397\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean -8.472759873257019e-06, std 0.020015262067317963\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean -1.7752179701346904e-05, std 0.019993437454104424\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean 3.5987050068797544e-05, std 0.020008893683552742\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean 1.0020009540312458e-05, std 0.02083071507513523\n",
      "name: bias, mean 0.00020686058269347996, std 0.02075640670955181\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean -5.178641458769562e-06, std 0.01041789073497057\n",
      "name: bias, mean -0.00013895162555854768, std 0.01084489468485117\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean 1.3448656318360008e-05, std 0.020010385662317276\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean -7.147422365960665e-06, std 0.02000848390161991\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean 4.6523713535862043e-05, std 0.020009001716971397\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean -8.472759873257019e-06, std 0.020015262067317963\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean -1.7752179701346904e-05, std 0.019993437454104424\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean 3.5987050068797544e-05, std 0.020008893683552742\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean 1.3448656318360008e-05, std 0.020010385662317276\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean -7.147422365960665e-06, std 0.02000848390161991\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 3.130952609353699e-05, std 0.02084173820912838\n",
      "name: bias, mean 0.00040799201815389097, std 0.021288784220814705\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 7.497720616811421e-06, std 0.020822102203965187\n",
      "name: bias, mean 0.0001066323384293355, std 0.02094654180109501\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -2.2607857772527495e-06, std 0.020829251036047935\n",
      "name: bias, mean -0.000800225418061018, std 0.021059973165392876\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.5980056559783407e-05, std 0.02083389274775982\n",
      "name: bias, mean -0.0005683436174876988, std 0.020137423649430275\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean -2.1744604055129457e-06, std 0.020006736740469933\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean -2.6225208785035647e-05, std 0.019996993243694305\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean 2.6104153221240267e-05, std 0.019996780902147293\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean -4.3162151996511966e-05, std 0.020009227097034454\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean -1.5138315575313754e-05, std 0.020846910774707794\n",
      "name: bias, mean -0.00021918928541708738, std 0.020819703117012978\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean 1.091030480893096e-05, std 0.010417287237942219\n",
      "name: bias, mean 0.0007934069726616144, std 0.01052520889788866\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean 2.333072006877046e-05, std 0.020019633695483208\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean 4.2682972889451776e-06, std 0.020010946318507195\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean -2.1744604055129457e-06, std 0.020006736740469933\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean -2.6225208785035647e-05, std 0.019996993243694305\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean 2.6104153221240267e-05, std 0.019996780902147293\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean -4.3162151996511966e-05, std 0.020009227097034454\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean 2.333072006877046e-05, std 0.020019633695483208\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean 4.2682972889451776e-06, std 0.020010946318507195\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -1.1523404282343108e-05, std 0.02085251919925213\n",
      "name: bias, mean -0.00021674188610631973, std 0.020436275750398636\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 5.1913906645495445e-05, std 0.02082326076924801\n",
      "name: bias, mean -0.00036263931542634964, std 0.021214090287685394\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -1.8027551504928852e-06, std 0.020825926214456558\n",
      "name: bias, mean -0.0006023160531185567, std 0.021097665652632713\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.391370369674405e-05, std 0.020867958664894104\n",
      "name: bias, mean 0.0009192526340484619, std 0.021011769771575928\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean 3.413425019971328e-06, std 0.019984818994998932\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean -2.6007690394180827e-05, std 0.019987376406788826\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean -1.4599173482565675e-05, std 0.020016849040985107\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean -1.8871585780289024e-05, std 0.02001277171075344\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean 9.217645128956065e-06, std 0.020841466262936592\n",
      "name: bias, mean 1.0940780157397967e-05, std 0.020716143772006035\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean 1.4594324056815822e-05, std 0.010411265306174755\n",
      "name: bias, mean -0.00029533167253248394, std 0.010455472394824028\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean 2.3277474610949866e-05, std 0.020003994926810265\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean -1.3764120012638159e-05, std 0.019998662173748016\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean 3.413425019971328e-06, std 0.019984818994998932\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean -2.6007690394180827e-05, std 0.019987376406788826\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean -1.4599173482565675e-05, std 0.020016849040985107\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean -1.8871585780289024e-05, std 0.02001277171075344\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean 2.3277474610949866e-05, std 0.020003994926810265\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean -1.3764120012638159e-05, std 0.019998662173748016\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.3268677321320865e-05, std 0.020836737006902695\n",
      "name: bias, mean 0.0005082884454168379, std 0.02072172425687313\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -3.051538260478992e-05, std 0.020826218649744987\n",
      "name: bias, mean -0.0008928051101975143, std 0.02052989788353443\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.1892954717040993e-05, std 0.020832732319831848\n",
      "name: bias, mean -6.118090095696971e-05, std 0.020978018641471863\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 2.6298668672097847e-05, std 0.020843518897891045\n",
      "name: bias, mean 5.035315916757099e-05, std 0.020949149504303932\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean 1.1460921996331308e-05, std 0.020019633695483208\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean 2.8963886506971903e-05, std 0.01996096596121788\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean 2.716574090300128e-05, std 0.019982296973466873\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean -3.403553273528814e-05, std 0.020036017522215843\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean 8.898970008885954e-06, std 0.020826540887355804\n",
      "name: bias, mean -0.00022533279843628407, std 0.020669477060437202\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean -1.0180616527577513e-06, std 0.01041672844439745\n",
      "name: bias, mean -0.0003545069193933159, std 0.010468273423612118\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean 6.70116719447833e-07, std 0.02001502923667431\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean 4.624300345312804e-06, std 0.019993551075458527\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean 1.1460921996331308e-05, std 0.020019633695483208\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean 2.8963886506971903e-05, std 0.01996096596121788\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean 2.716574090300128e-05, std 0.019982296973466873\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean -3.403553273528814e-05, std 0.020036017522215843\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean 6.70116719447833e-07, std 0.02001502923667431\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean 4.624300345312804e-06, std 0.019993551075458527\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -1.0076271792058833e-05, std 0.020842552185058594\n",
      "name: bias, mean -0.0005649150698445737, std 0.020892281085252762\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -2.4066535843303427e-05, std 0.020810997113585472\n",
      "name: bias, mean 5.78569779463578e-05, std 0.020547442138195038\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 7.650102816114668e-06, std 0.020837226882576942\n",
      "name: bias, mean 0.0011722211493179202, std 0.02095302939414978\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 5.192764365347102e-05, std 0.020849743857979774\n",
      "name: bias, mean 0.0006000075954943895, std 0.020393453538417816\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean -2.194212129325024e-06, std 0.019984442740678787\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean -2.0062127532582963e-06, std 0.019954385235905647\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean 1.2051499652443454e-05, std 0.020011652261018753\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean -3.5922152164857835e-05, std 0.02000410109758377\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean -7.358810762525536e-06, std 0.02084052748978138\n",
      "name: bias, mean 0.00023386802058666945, std 0.020499249920248985\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean 9.647460501582827e-06, std 0.01041971705853939\n",
      "name: bias, mean -0.000498435168992728, std 0.010419553145766258\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean -1.6914186744543258e-06, std 0.01999736949801445\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean -7.12141229541885e-07, std 0.02000707946717739\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean -2.194212129325024e-06, std 0.019984442740678787\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean -2.0062127532582963e-06, std 0.019954385235905647\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean 1.2051499652443454e-05, std 0.020011652261018753\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean -3.5922152164857835e-05, std 0.02000410109758377\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean -1.6914186744543258e-06, std 0.01999736949801445\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean -7.12141229541885e-07, std 0.02000707946717739\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.3502299225365277e-05, std 0.020839838311076164\n",
      "name: bias, mean -0.0003990881086792797, std 0.020942214876413345\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 4.14303649449721e-05, std 0.020830024033784866\n",
      "name: bias, mean -0.00017792619473766536, std 0.0207926444709301\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.6147352653206326e-05, std 0.020826011896133423\n",
      "name: bias, mean -0.0013489077100530267, std 0.020775195211172104\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 3.7443722249008715e-05, std 0.020849891006946564\n",
      "name: bias, mean -0.0009275394841097295, std 0.02077391743659973\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean -2.0796016997337574e-06, std 0.020018132403492928\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean -3.9545899198856205e-05, std 0.020005011931061745\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean -1.4027535144123249e-05, std 0.01998085342347622\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean 4.83102812722791e-05, std 0.02000616490840912\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean 2.7231826607021503e-06, std 0.020831981673836708\n",
      "name: bias, mean -0.0002559510467108339, std 0.021149424836039543\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean -1.5043977327877656e-05, std 0.010416491888463497\n",
      "name: bias, mean -0.00030320309451781213, std 0.010247181169688702\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean -5.972398412268376e-06, std 0.020002026110887527\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean -1.8856047972803935e-05, std 0.020008984953165054\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean -2.0796016997337574e-06, std 0.020018132403492928\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean -3.9545899198856205e-05, std 0.020005011931061745\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean -1.4027535144123249e-05, std 0.01998085342347622\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean 4.83102812722791e-05, std 0.02000616490840912\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean -5.972398412268376e-06, std 0.020002026110887527\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean -1.8856047972803935e-05, std 0.020008984953165054\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -2.4748031137278304e-05, std 0.020854828879237175\n",
      "name: bias, mean -0.0011378017952665687, std 0.020911775529384613\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 2.2540784812008496e-06, std 0.02083940990269184\n",
      "name: bias, mean -0.0013303771847859025, std 0.02122172713279724\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.2710857845377177e-05, std 0.020830808207392693\n",
      "name: bias, mean -0.00035915759508498013, std 0.02069500833749771\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 1.3321935057319934e-06, std 0.02082761749625206\n",
      "name: bias, mean -0.0017107869498431683, std 0.020833401009440422\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean -3.2998505048453808e-06, std 0.020005270838737488\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean 1.3545891306421254e-05, std 0.02001049555838108\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean -1.8830171029549092e-05, std 0.019971340894699097\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean -4.0821305447025225e-05, std 0.02000979147851467\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean -4.603361503541237e-06, std 0.020821843296289444\n",
      "name: bias, mean 0.00038679875433444977, std 0.020766913890838623\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean 6.879958164063282e-06, std 0.010415513068437576\n",
      "name: bias, mean -8.896542567526922e-05, std 0.010545770637691021\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean -1.6561467418796383e-05, std 0.019989371299743652\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean -5.525362212210894e-06, std 0.01999773643910885\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean -3.2998505048453808e-06, std 0.020005270838737488\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean 1.3545891306421254e-05, std 0.02001049555838108\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean -1.8830171029549092e-05, std 0.019971340894699097\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean -4.0821305447025225e-05, std 0.02000979147851467\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean -1.6561467418796383e-05, std 0.019989371299743652\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean -5.525362212210894e-06, std 0.01999773643910885\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -1.8078253560815938e-05, std 0.020818419754505157\n",
      "name: bias, mean 0.0005752193392254412, std 0.0210686344653368\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -3.481798557913862e-05, std 0.020820818841457367\n",
      "name: bias, mean -0.0011520003899931908, std 0.020939495414495468\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean 3.456061222095741e-06, std 0.02082417905330658\n",
      "name: bias, mean 0.0007457874598912895, std 0.021257765591144562\n",
      "--------\n",
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "name: weight, mean -2.6465133942110697e-06, std 0.02083740569651127\n",
      "name: bias, mean 2.4529872462153435e-06, std 0.021328022703528404\n",
      "--------\n",
      "Wav2Vec2SdpaAttention(\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "name: k_proj.weight, mean -4.472724685911089e-05, std 0.019983135163784027\n",
      "name: k_proj.bias, mean 0.0, std 0.0\n",
      "name: v_proj.weight, mean -1.9420353055465966e-05, std 0.019999338313937187\n",
      "name: v_proj.bias, mean 0.0, std 0.0\n",
      "name: q_proj.weight, mean 2.5973349693231285e-07, std 0.020028045400977135\n",
      "name: q_proj.bias, mean 0.0, std 0.0\n",
      "name: out_proj.weight, mean 2.6678608264774084e-06, std 0.019984198734164238\n",
      "name: out_proj.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Linear(in_features=768, out_features=3072, bias=True)\n",
      "name: weight, mean 1.2093589248252101e-05, std 0.02083330787718296\n",
      "name: bias, mean 0.0001029430641210638, std 0.020958947017788887\n",
      "--------\n",
      "GELUActivation()\n",
      "--------\n",
      "Linear(in_features=3072, out_features=768, bias=True)\n",
      "name: weight, mean 6.727441359544173e-07, std 0.010415182448923588\n",
      "name: bias, mean 0.0002297236496815458, std 0.010513446293771267\n",
      "--------\n",
      "Dropout(p=0.0, inplace=False)\n",
      "--------\n",
      "Wav2Vec2FeedForward(\n",
      "  (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (intermediate_act_fn): GELUActivation()\n",
      "  (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (output_dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "name: intermediate_dense.weight, mean -5.902873908780748e-06, std 0.01998891867697239\n",
      "name: intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: output_dense.weight, mean 1.3053840120846871e-05, std 0.02000267058610916\n",
      "name: output_dense.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "name: weight, mean 1.0, std 0.0\n",
      "name: bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "  (attention): Wav2Vec2SdpaAttention(\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (feed_forward): Wav2Vec2FeedForward(\n",
      "    (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "    (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "name: attention.k_proj.weight, mean -4.472724685911089e-05, std 0.019983135163784027\n",
      "name: attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.v_proj.weight, mean -1.9420353055465966e-05, std 0.019999338313937187\n",
      "name: attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.q_proj.weight, mean 2.5973349693231285e-07, std 0.020028045400977135\n",
      "name: attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: attention.out_proj.weight, mean 2.6678608264774084e-06, std 0.019984198734164238\n",
      "name: attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.intermediate_dense.weight, mean -5.902873908780748e-06, std 0.01998891867697239\n",
      "name: feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: feed_forward.output_dense.weight, mean 1.3053840120846871e-05, std 0.02000267058610916\n",
      "name: feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "ModuleList(\n",
      "  (0-11): 12 x Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "    (attention): Wav2Vec2SdpaAttention(\n",
      "      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (feed_forward): Wav2Vec2FeedForward(\n",
      "      (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "      (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (intermediate_act_fn): GELUActivation()\n",
      "      (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "name: 0.attention.k_proj.weight, mean 1.0291325452271849e-05, std 0.019992340356111526\n",
      "name: 0.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 0.attention.v_proj.weight, mean -2.940171179943718e-05, std 0.01997837796807289\n",
      "name: 0.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 0.attention.q_proj.weight, mean 2.2064874428906478e-05, std 0.020014507696032524\n",
      "name: 0.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 0.attention.out_proj.weight, mean 2.773741698547383e-06, std 0.019974686205387115\n",
      "name: 0.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 0.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 0.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 0.feed_forward.intermediate_dense.weight, mean 2.045001383521594e-05, std 0.020001910626888275\n",
      "name: 0.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 0.feed_forward.output_dense.weight, mean -6.6482816691859625e-06, std 0.020012028515338898\n",
      "name: 0.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 0.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 0.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 1.attention.k_proj.weight, mean -3.5533259506337345e-05, std 0.020023051649332047\n",
      "name: 1.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 1.attention.v_proj.weight, mean -3.307362203486264e-05, std 0.020003318786621094\n",
      "name: 1.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 1.attention.q_proj.weight, mean 1.3059252523817122e-05, std 0.020004164427518845\n",
      "name: 1.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 1.attention.out_proj.weight, mean 2.397509706497658e-05, std 0.019984198734164238\n",
      "name: 1.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 1.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 1.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 1.feed_forward.intermediate_dense.weight, mean 3.714662625498022e-06, std 0.02000550739467144\n",
      "name: 1.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 1.feed_forward.output_dense.weight, mean 2.4925735488068312e-05, std 0.02000564895570278\n",
      "name: 1.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 1.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 1.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 2.attention.k_proj.weight, mean -1.0827562618942466e-05, std 0.019993958994746208\n",
      "name: 2.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 2.attention.v_proj.weight, mean 3.789313495872193e-06, std 0.019967161118984222\n",
      "name: 2.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 2.attention.q_proj.weight, mean 4.3217369238846004e-05, std 0.019983502104878426\n",
      "name: 2.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 2.attention.out_proj.weight, mean -3.928915612050332e-05, std 0.019979378208518028\n",
      "name: 2.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 2.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 2.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 2.feed_forward.intermediate_dense.weight, mean -2.6740803150460124e-05, std 0.019988693296909332\n",
      "name: 2.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 2.feed_forward.output_dense.weight, mean 8.920041182136629e-06, std 0.02000530995428562\n",
      "name: 2.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 2.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 2.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 3.attention.k_proj.weight, mean 2.0223720639478415e-05, std 0.02001813054084778\n",
      "name: 3.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 3.attention.v_proj.weight, mean 2.672090158739593e-05, std 0.019983235746622086\n",
      "name: 3.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 3.attention.q_proj.weight, mean 1.2204828635731246e-05, std 0.019986022263765335\n",
      "name: 3.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 3.attention.out_proj.weight, mean 3.982783164246939e-05, std 0.020009377971291542\n",
      "name: 3.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 3.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 3.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 3.feed_forward.intermediate_dense.weight, mean -2.051756837317953e-06, std 0.020013613626360893\n",
      "name: 3.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 3.feed_forward.output_dense.weight, mean -1.8938973880722187e-05, std 0.019999446347355843\n",
      "name: 3.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 3.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 3.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 4.attention.k_proj.weight, mean 4.6523713535862043e-05, std 0.020009001716971397\n",
      "name: 4.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 4.attention.v_proj.weight, mean -8.472759873257019e-06, std 0.020015262067317963\n",
      "name: 4.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 4.attention.q_proj.weight, mean -1.7752179701346904e-05, std 0.019993437454104424\n",
      "name: 4.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 4.attention.out_proj.weight, mean 3.5987050068797544e-05, std 0.020008893683552742\n",
      "name: 4.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 4.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 4.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 4.feed_forward.intermediate_dense.weight, mean 1.3448656318360008e-05, std 0.020010385662317276\n",
      "name: 4.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 4.feed_forward.output_dense.weight, mean -7.147422365960665e-06, std 0.02000848390161991\n",
      "name: 4.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 4.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 4.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 5.attention.k_proj.weight, mean -2.1744604055129457e-06, std 0.020006736740469933\n",
      "name: 5.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 5.attention.v_proj.weight, mean -2.6225208785035647e-05, std 0.019996993243694305\n",
      "name: 5.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 5.attention.q_proj.weight, mean 2.6104153221240267e-05, std 0.019996780902147293\n",
      "name: 5.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 5.attention.out_proj.weight, mean -4.3162151996511966e-05, std 0.020009227097034454\n",
      "name: 5.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 5.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 5.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 5.feed_forward.intermediate_dense.weight, mean 2.333072006877046e-05, std 0.020019633695483208\n",
      "name: 5.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 5.feed_forward.output_dense.weight, mean 4.2682972889451776e-06, std 0.020010946318507195\n",
      "name: 5.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 5.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 5.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 6.attention.k_proj.weight, mean 3.413425019971328e-06, std 0.019984818994998932\n",
      "name: 6.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 6.attention.v_proj.weight, mean -2.6007690394180827e-05, std 0.019987376406788826\n",
      "name: 6.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 6.attention.q_proj.weight, mean -1.4599173482565675e-05, std 0.020016849040985107\n",
      "name: 6.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 6.attention.out_proj.weight, mean -1.8871585780289024e-05, std 0.02001277171075344\n",
      "name: 6.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 6.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 6.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 6.feed_forward.intermediate_dense.weight, mean 2.3277474610949866e-05, std 0.020003994926810265\n",
      "name: 6.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 6.feed_forward.output_dense.weight, mean -1.3764120012638159e-05, std 0.019998662173748016\n",
      "name: 6.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 6.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 6.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 7.attention.k_proj.weight, mean 1.1460921996331308e-05, std 0.020019633695483208\n",
      "name: 7.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 7.attention.v_proj.weight, mean 2.8963886506971903e-05, std 0.01996096596121788\n",
      "name: 7.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 7.attention.q_proj.weight, mean 2.716574090300128e-05, std 0.019982296973466873\n",
      "name: 7.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 7.attention.out_proj.weight, mean -3.403553273528814e-05, std 0.020036017522215843\n",
      "name: 7.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 7.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 7.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 7.feed_forward.intermediate_dense.weight, mean 6.70116719447833e-07, std 0.02001502923667431\n",
      "name: 7.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 7.feed_forward.output_dense.weight, mean 4.624300345312804e-06, std 0.019993551075458527\n",
      "name: 7.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 7.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 7.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 8.attention.k_proj.weight, mean -2.194212129325024e-06, std 0.019984442740678787\n",
      "name: 8.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 8.attention.v_proj.weight, mean -2.0062127532582963e-06, std 0.019954385235905647\n",
      "name: 8.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 8.attention.q_proj.weight, mean 1.2051499652443454e-05, std 0.020011652261018753\n",
      "name: 8.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 8.attention.out_proj.weight, mean -3.5922152164857835e-05, std 0.02000410109758377\n",
      "name: 8.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 8.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 8.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 8.feed_forward.intermediate_dense.weight, mean -1.6914186744543258e-06, std 0.01999736949801445\n",
      "name: 8.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 8.feed_forward.output_dense.weight, mean -7.12141229541885e-07, std 0.02000707946717739\n",
      "name: 8.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 8.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 8.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 9.attention.k_proj.weight, mean -2.0796016997337574e-06, std 0.020018132403492928\n",
      "name: 9.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 9.attention.v_proj.weight, mean -3.9545899198856205e-05, std 0.020005011931061745\n",
      "name: 9.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 9.attention.q_proj.weight, mean -1.4027535144123249e-05, std 0.01998085342347622\n",
      "name: 9.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 9.attention.out_proj.weight, mean 4.83102812722791e-05, std 0.02000616490840912\n",
      "name: 9.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 9.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 9.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 9.feed_forward.intermediate_dense.weight, mean -5.972398412268376e-06, std 0.020002026110887527\n",
      "name: 9.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 9.feed_forward.output_dense.weight, mean -1.8856047972803935e-05, std 0.020008984953165054\n",
      "name: 9.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 9.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 9.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 10.attention.k_proj.weight, mean -3.2998505048453808e-06, std 0.020005270838737488\n",
      "name: 10.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 10.attention.v_proj.weight, mean 1.3545891306421254e-05, std 0.02001049555838108\n",
      "name: 10.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 10.attention.q_proj.weight, mean -1.8830171029549092e-05, std 0.019971340894699097\n",
      "name: 10.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 10.attention.out_proj.weight, mean -4.0821305447025225e-05, std 0.02000979147851467\n",
      "name: 10.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 10.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 10.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 10.feed_forward.intermediate_dense.weight, mean -1.6561467418796383e-05, std 0.019989371299743652\n",
      "name: 10.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 10.feed_forward.output_dense.weight, mean -5.525362212210894e-06, std 0.01999773643910885\n",
      "name: 10.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 10.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 10.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 11.attention.k_proj.weight, mean -4.472724685911089e-05, std 0.019983135163784027\n",
      "name: 11.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: 11.attention.v_proj.weight, mean -1.9420353055465966e-05, std 0.019999338313937187\n",
      "name: 11.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: 11.attention.q_proj.weight, mean 2.5973349693231285e-07, std 0.020028045400977135\n",
      "name: 11.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: 11.attention.out_proj.weight, mean 2.6678608264774084e-06, std 0.019984198734164238\n",
      "name: 11.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: 11.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 11.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: 11.feed_forward.intermediate_dense.weight, mean -5.902873908780748e-06, std 0.01998891867697239\n",
      "name: 11.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: 11.feed_forward.output_dense.weight, mean 1.3053840120846871e-05, std 0.02000267058610916\n",
      "name: 11.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: 11.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: 11.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2EncoderStableLayerNorm(\n",
      "  (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "    (conv): ParametrizedConv1d(\n",
      "      768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "      (parametrizations): ModuleDict(\n",
      "        (weight): ParametrizationList(\n",
      "          (0): _WeightNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (padding): Wav2Vec2SamePadLayer()\n",
      "    (activation): GELUActivation()\n",
      "  )\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0-11): 12 x Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "      (attention): Wav2Vec2SdpaAttention(\n",
      "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): Wav2Vec2FeedForward(\n",
      "        (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (intermediate_act_fn): GELUActivation()\n",
      "        (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "name: pos_conv_embed.conv.bias, mean 0.0, std 0.0\n",
      "name: pos_conv_embed.conv.parametrizations.weight.original0, mean 1.4145300388336182, std 0.0034867976792156696\n",
      "name: pos_conv_embed.conv.parametrizations.weight.original1, mean -2.3635434445168357e-06, std 0.007367375306785107\n",
      "name: layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.0.attention.k_proj.weight, mean 1.0291325452271849e-05, std 0.019992340356111526\n",
      "name: layers.0.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.0.attention.v_proj.weight, mean -2.940171179943718e-05, std 0.01997837796807289\n",
      "name: layers.0.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.0.attention.q_proj.weight, mean 2.2064874428906478e-05, std 0.020014507696032524\n",
      "name: layers.0.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.0.attention.out_proj.weight, mean 2.773741698547383e-06, std 0.019974686205387115\n",
      "name: layers.0.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.0.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.0.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.0.feed_forward.intermediate_dense.weight, mean 2.045001383521594e-05, std 0.020001910626888275\n",
      "name: layers.0.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.0.feed_forward.output_dense.weight, mean -6.6482816691859625e-06, std 0.020012028515338898\n",
      "name: layers.0.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.0.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.0.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.1.attention.k_proj.weight, mean -3.5533259506337345e-05, std 0.020023051649332047\n",
      "name: layers.1.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.1.attention.v_proj.weight, mean -3.307362203486264e-05, std 0.020003318786621094\n",
      "name: layers.1.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.1.attention.q_proj.weight, mean 1.3059252523817122e-05, std 0.020004164427518845\n",
      "name: layers.1.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.1.attention.out_proj.weight, mean 2.397509706497658e-05, std 0.019984198734164238\n",
      "name: layers.1.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.1.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.1.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.1.feed_forward.intermediate_dense.weight, mean 3.714662625498022e-06, std 0.02000550739467144\n",
      "name: layers.1.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.1.feed_forward.output_dense.weight, mean 2.4925735488068312e-05, std 0.02000564895570278\n",
      "name: layers.1.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.1.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.1.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.2.attention.k_proj.weight, mean -1.0827562618942466e-05, std 0.019993958994746208\n",
      "name: layers.2.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.2.attention.v_proj.weight, mean 3.789313495872193e-06, std 0.019967161118984222\n",
      "name: layers.2.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.2.attention.q_proj.weight, mean 4.3217369238846004e-05, std 0.019983502104878426\n",
      "name: layers.2.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.2.attention.out_proj.weight, mean -3.928915612050332e-05, std 0.019979378208518028\n",
      "name: layers.2.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.2.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.2.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.2.feed_forward.intermediate_dense.weight, mean -2.6740803150460124e-05, std 0.019988693296909332\n",
      "name: layers.2.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.2.feed_forward.output_dense.weight, mean 8.920041182136629e-06, std 0.02000530995428562\n",
      "name: layers.2.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.2.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.2.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.3.attention.k_proj.weight, mean 2.0223720639478415e-05, std 0.02001813054084778\n",
      "name: layers.3.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.3.attention.v_proj.weight, mean 2.672090158739593e-05, std 0.019983235746622086\n",
      "name: layers.3.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.3.attention.q_proj.weight, mean 1.2204828635731246e-05, std 0.019986022263765335\n",
      "name: layers.3.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.3.attention.out_proj.weight, mean 3.982783164246939e-05, std 0.020009377971291542\n",
      "name: layers.3.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.3.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.3.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.3.feed_forward.intermediate_dense.weight, mean -2.051756837317953e-06, std 0.020013613626360893\n",
      "name: layers.3.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.3.feed_forward.output_dense.weight, mean -1.8938973880722187e-05, std 0.019999446347355843\n",
      "name: layers.3.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.3.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.3.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.4.attention.k_proj.weight, mean 4.6523713535862043e-05, std 0.020009001716971397\n",
      "name: layers.4.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.4.attention.v_proj.weight, mean -8.472759873257019e-06, std 0.020015262067317963\n",
      "name: layers.4.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.4.attention.q_proj.weight, mean -1.7752179701346904e-05, std 0.019993437454104424\n",
      "name: layers.4.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.4.attention.out_proj.weight, mean 3.5987050068797544e-05, std 0.020008893683552742\n",
      "name: layers.4.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.4.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.4.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.4.feed_forward.intermediate_dense.weight, mean 1.3448656318360008e-05, std 0.020010385662317276\n",
      "name: layers.4.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.4.feed_forward.output_dense.weight, mean -7.147422365960665e-06, std 0.02000848390161991\n",
      "name: layers.4.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.4.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.4.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.5.attention.k_proj.weight, mean -2.1744604055129457e-06, std 0.020006736740469933\n",
      "name: layers.5.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.5.attention.v_proj.weight, mean -2.6225208785035647e-05, std 0.019996993243694305\n",
      "name: layers.5.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.5.attention.q_proj.weight, mean 2.6104153221240267e-05, std 0.019996780902147293\n",
      "name: layers.5.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.5.attention.out_proj.weight, mean -4.3162151996511966e-05, std 0.020009227097034454\n",
      "name: layers.5.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.5.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.5.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.5.feed_forward.intermediate_dense.weight, mean 2.333072006877046e-05, std 0.020019633695483208\n",
      "name: layers.5.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.5.feed_forward.output_dense.weight, mean 4.2682972889451776e-06, std 0.020010946318507195\n",
      "name: layers.5.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.5.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.5.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.6.attention.k_proj.weight, mean 3.413425019971328e-06, std 0.019984818994998932\n",
      "name: layers.6.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.6.attention.v_proj.weight, mean -2.6007690394180827e-05, std 0.019987376406788826\n",
      "name: layers.6.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.6.attention.q_proj.weight, mean -1.4599173482565675e-05, std 0.020016849040985107\n",
      "name: layers.6.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.6.attention.out_proj.weight, mean -1.8871585780289024e-05, std 0.02001277171075344\n",
      "name: layers.6.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.6.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.6.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.6.feed_forward.intermediate_dense.weight, mean 2.3277474610949866e-05, std 0.020003994926810265\n",
      "name: layers.6.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.6.feed_forward.output_dense.weight, mean -1.3764120012638159e-05, std 0.019998662173748016\n",
      "name: layers.6.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.6.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.6.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.7.attention.k_proj.weight, mean 1.1460921996331308e-05, std 0.020019633695483208\n",
      "name: layers.7.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.7.attention.v_proj.weight, mean 2.8963886506971903e-05, std 0.01996096596121788\n",
      "name: layers.7.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.7.attention.q_proj.weight, mean 2.716574090300128e-05, std 0.019982296973466873\n",
      "name: layers.7.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.7.attention.out_proj.weight, mean -3.403553273528814e-05, std 0.020036017522215843\n",
      "name: layers.7.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.7.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.7.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.7.feed_forward.intermediate_dense.weight, mean 6.70116719447833e-07, std 0.02001502923667431\n",
      "name: layers.7.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.7.feed_forward.output_dense.weight, mean 4.624300345312804e-06, std 0.019993551075458527\n",
      "name: layers.7.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.7.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.7.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.8.attention.k_proj.weight, mean -2.194212129325024e-06, std 0.019984442740678787\n",
      "name: layers.8.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.8.attention.v_proj.weight, mean -2.0062127532582963e-06, std 0.019954385235905647\n",
      "name: layers.8.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.8.attention.q_proj.weight, mean 1.2051499652443454e-05, std 0.020011652261018753\n",
      "name: layers.8.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.8.attention.out_proj.weight, mean -3.5922152164857835e-05, std 0.02000410109758377\n",
      "name: layers.8.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.8.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.8.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.8.feed_forward.intermediate_dense.weight, mean -1.6914186744543258e-06, std 0.01999736949801445\n",
      "name: layers.8.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.8.feed_forward.output_dense.weight, mean -7.12141229541885e-07, std 0.02000707946717739\n",
      "name: layers.8.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.8.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.8.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.9.attention.k_proj.weight, mean -2.0796016997337574e-06, std 0.020018132403492928\n",
      "name: layers.9.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.9.attention.v_proj.weight, mean -3.9545899198856205e-05, std 0.020005011931061745\n",
      "name: layers.9.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.9.attention.q_proj.weight, mean -1.4027535144123249e-05, std 0.01998085342347622\n",
      "name: layers.9.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.9.attention.out_proj.weight, mean 4.83102812722791e-05, std 0.02000616490840912\n",
      "name: layers.9.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.9.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.9.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.9.feed_forward.intermediate_dense.weight, mean -5.972398412268376e-06, std 0.020002026110887527\n",
      "name: layers.9.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.9.feed_forward.output_dense.weight, mean -1.8856047972803935e-05, std 0.020008984953165054\n",
      "name: layers.9.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.9.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.9.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.10.attention.k_proj.weight, mean -3.2998505048453808e-06, std 0.020005270838737488\n",
      "name: layers.10.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.10.attention.v_proj.weight, mean 1.3545891306421254e-05, std 0.02001049555838108\n",
      "name: layers.10.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.10.attention.q_proj.weight, mean -1.8830171029549092e-05, std 0.019971340894699097\n",
      "name: layers.10.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.10.attention.out_proj.weight, mean -4.0821305447025225e-05, std 0.02000979147851467\n",
      "name: layers.10.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.10.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.10.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.10.feed_forward.intermediate_dense.weight, mean -1.6561467418796383e-05, std 0.019989371299743652\n",
      "name: layers.10.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.10.feed_forward.output_dense.weight, mean -5.525362212210894e-06, std 0.01999773643910885\n",
      "name: layers.10.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.10.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.10.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.11.attention.k_proj.weight, mean -4.472724685911089e-05, std 0.019983135163784027\n",
      "name: layers.11.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.11.attention.v_proj.weight, mean -1.9420353055465966e-05, std 0.019999338313937187\n",
      "name: layers.11.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.11.attention.q_proj.weight, mean 2.5973349693231285e-07, std 0.020028045400977135\n",
      "name: layers.11.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.11.attention.out_proj.weight, mean 2.6678608264774084e-06, std 0.019984198734164238\n",
      "name: layers.11.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: layers.11.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.11.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: layers.11.feed_forward.intermediate_dense.weight, mean -5.902873908780748e-06, std 0.01998891867697239\n",
      "name: layers.11.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.11.feed_forward.output_dense.weight, mean 1.3053840120846871e-05, std 0.02000267058610916\n",
      "name: layers.11.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: layers.11.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: layers.11.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "--------\n",
      "Wav2Vec2Model(\n",
      "  (feature_extractor): Wav2Vec2FeatureEncoder(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Wav2Vec2LayerNormConvLayer(\n",
      "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_projection): Wav2Vec2FeatureProjection(\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
      "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "      (conv): ParametrizedConv1d(\n",
      "        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "        (parametrizations): ModuleDict(\n",
      "          (weight): ParametrizationList(\n",
      "            (0): _WeightNorm()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (padding): Wav2Vec2SamePadLayer()\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x Wav2Vec2EncoderLayerStableLayerNorm(\n",
      "        (attention): Wav2Vec2SdpaAttention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "name: masked_spec_embed, mean 0.5088047385215759, std 0.2929269075393677\n",
      "name: feature_extractor.conv_layers.0.conv.weight, mean -0.0025054551661014557, std 0.4455367922782898\n",
      "name: feature_extractor.conv_layers.0.conv.bias, mean -0.0032587391324341297, std 0.18554647266864777\n",
      "name: feature_extractor.conv_layers.0.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: feature_extractor.conv_layers.0.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feature_extractor.conv_layers.1.conv.weight, mean -5.046659498475492e-05, std 0.036100123077631\n",
      "name: feature_extractor.conv_layers.1.conv.bias, mean 0.0009091057581827044, std 0.014743977226316929\n",
      "name: feature_extractor.conv_layers.1.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: feature_extractor.conv_layers.1.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feature_extractor.conv_layers.2.conv.weight, mean 2.352310985997974e-07, std 0.03607241064310074\n",
      "name: feature_extractor.conv_layers.2.conv.bias, mean -0.0010985223343595862, std 0.015055416151881218\n",
      "name: feature_extractor.conv_layers.2.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: feature_extractor.conv_layers.2.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feature_extractor.conv_layers.3.conv.weight, mean -1.0806208592839539e-05, std 0.036102764308452606\n",
      "name: feature_extractor.conv_layers.3.conv.bias, mean 0.0004939131904393435, std 0.015146415680646896\n",
      "name: feature_extractor.conv_layers.3.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: feature_extractor.conv_layers.3.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feature_extractor.conv_layers.4.conv.weight, mean 4.364449341665022e-05, std 0.03609722480177879\n",
      "name: feature_extractor.conv_layers.4.conv.bias, mean -8.567776239942759e-05, std 0.014661132358014584\n",
      "name: feature_extractor.conv_layers.4.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: feature_extractor.conv_layers.4.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feature_extractor.conv_layers.5.conv.weight, mean 2.196892091888003e-05, std 0.04419323801994324\n",
      "name: feature_extractor.conv_layers.5.conv.bias, mean -0.0007734612445347011, std 0.0177419725805521\n",
      "name: feature_extractor.conv_layers.5.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: feature_extractor.conv_layers.5.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feature_extractor.conv_layers.6.conv.weight, mean -3.9847378502599895e-05, std 0.044176314026117325\n",
      "name: feature_extractor.conv_layers.6.conv.bias, mean -0.0019032731652259827, std 0.017737187445163727\n",
      "name: feature_extractor.conv_layers.6.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: feature_extractor.conv_layers.6.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feature_projection.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: feature_projection.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: feature_projection.projection.weight, mean 1.8233713490189984e-06, std 0.02552342787384987\n",
      "name: feature_projection.projection.bias, mean -0.001443911693058908, std 0.02610066346824169\n",
      "name: encoder.pos_conv_embed.conv.bias, mean 0.0, std 0.0\n",
      "name: encoder.pos_conv_embed.conv.parametrizations.weight.original0, mean 1.4145300388336182, std 0.0034867976792156696\n",
      "name: encoder.pos_conv_embed.conv.parametrizations.weight.original1, mean -2.3635434445168357e-06, std 0.007367375306785107\n",
      "name: encoder.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.0.attention.k_proj.weight, mean 1.0291325452271849e-05, std 0.019992340356111526\n",
      "name: encoder.layers.0.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.0.attention.v_proj.weight, mean -2.940171179943718e-05, std 0.01997837796807289\n",
      "name: encoder.layers.0.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.0.attention.q_proj.weight, mean 2.2064874428906478e-05, std 0.020014507696032524\n",
      "name: encoder.layers.0.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.0.attention.out_proj.weight, mean 2.773741698547383e-06, std 0.019974686205387115\n",
      "name: encoder.layers.0.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.0.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.0.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.0.feed_forward.intermediate_dense.weight, mean 2.045001383521594e-05, std 0.020001910626888275\n",
      "name: encoder.layers.0.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.0.feed_forward.output_dense.weight, mean -6.6482816691859625e-06, std 0.020012028515338898\n",
      "name: encoder.layers.0.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.0.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.0.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.1.attention.k_proj.weight, mean -3.5533259506337345e-05, std 0.020023051649332047\n",
      "name: encoder.layers.1.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.1.attention.v_proj.weight, mean -3.307362203486264e-05, std 0.020003318786621094\n",
      "name: encoder.layers.1.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.1.attention.q_proj.weight, mean 1.3059252523817122e-05, std 0.020004164427518845\n",
      "name: encoder.layers.1.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.1.attention.out_proj.weight, mean 2.397509706497658e-05, std 0.019984198734164238\n",
      "name: encoder.layers.1.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.1.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.1.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.1.feed_forward.intermediate_dense.weight, mean 3.714662625498022e-06, std 0.02000550739467144\n",
      "name: encoder.layers.1.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.1.feed_forward.output_dense.weight, mean 2.4925735488068312e-05, std 0.02000564895570278\n",
      "name: encoder.layers.1.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.1.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.1.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.2.attention.k_proj.weight, mean -1.0827562618942466e-05, std 0.019993958994746208\n",
      "name: encoder.layers.2.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.2.attention.v_proj.weight, mean 3.789313495872193e-06, std 0.019967161118984222\n",
      "name: encoder.layers.2.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.2.attention.q_proj.weight, mean 4.3217369238846004e-05, std 0.019983502104878426\n",
      "name: encoder.layers.2.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.2.attention.out_proj.weight, mean -3.928915612050332e-05, std 0.019979378208518028\n",
      "name: encoder.layers.2.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.2.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.2.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.2.feed_forward.intermediate_dense.weight, mean -2.6740803150460124e-05, std 0.019988693296909332\n",
      "name: encoder.layers.2.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.2.feed_forward.output_dense.weight, mean 8.920041182136629e-06, std 0.02000530995428562\n",
      "name: encoder.layers.2.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.2.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.2.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.3.attention.k_proj.weight, mean 2.0223720639478415e-05, std 0.02001813054084778\n",
      "name: encoder.layers.3.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.3.attention.v_proj.weight, mean 2.672090158739593e-05, std 0.019983235746622086\n",
      "name: encoder.layers.3.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.3.attention.q_proj.weight, mean 1.2204828635731246e-05, std 0.019986022263765335\n",
      "name: encoder.layers.3.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.3.attention.out_proj.weight, mean 3.982783164246939e-05, std 0.020009377971291542\n",
      "name: encoder.layers.3.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.3.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.3.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.3.feed_forward.intermediate_dense.weight, mean -2.051756837317953e-06, std 0.020013613626360893\n",
      "name: encoder.layers.3.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.3.feed_forward.output_dense.weight, mean -1.8938973880722187e-05, std 0.019999446347355843\n",
      "name: encoder.layers.3.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.3.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.3.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.4.attention.k_proj.weight, mean 4.6523713535862043e-05, std 0.020009001716971397\n",
      "name: encoder.layers.4.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.4.attention.v_proj.weight, mean -8.472759873257019e-06, std 0.020015262067317963\n",
      "name: encoder.layers.4.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.4.attention.q_proj.weight, mean -1.7752179701346904e-05, std 0.019993437454104424\n",
      "name: encoder.layers.4.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.4.attention.out_proj.weight, mean 3.5987050068797544e-05, std 0.020008893683552742\n",
      "name: encoder.layers.4.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.4.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.4.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.4.feed_forward.intermediate_dense.weight, mean 1.3448656318360008e-05, std 0.020010385662317276\n",
      "name: encoder.layers.4.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.4.feed_forward.output_dense.weight, mean -7.147422365960665e-06, std 0.02000848390161991\n",
      "name: encoder.layers.4.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.4.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.4.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.5.attention.k_proj.weight, mean -2.1744604055129457e-06, std 0.020006736740469933\n",
      "name: encoder.layers.5.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.5.attention.v_proj.weight, mean -2.6225208785035647e-05, std 0.019996993243694305\n",
      "name: encoder.layers.5.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.5.attention.q_proj.weight, mean 2.6104153221240267e-05, std 0.019996780902147293\n",
      "name: encoder.layers.5.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.5.attention.out_proj.weight, mean -4.3162151996511966e-05, std 0.020009227097034454\n",
      "name: encoder.layers.5.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.5.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.5.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.5.feed_forward.intermediate_dense.weight, mean 2.333072006877046e-05, std 0.020019633695483208\n",
      "name: encoder.layers.5.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.5.feed_forward.output_dense.weight, mean 4.2682972889451776e-06, std 0.020010946318507195\n",
      "name: encoder.layers.5.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.5.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.5.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.6.attention.k_proj.weight, mean 3.413425019971328e-06, std 0.019984818994998932\n",
      "name: encoder.layers.6.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.6.attention.v_proj.weight, mean -2.6007690394180827e-05, std 0.019987376406788826\n",
      "name: encoder.layers.6.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.6.attention.q_proj.weight, mean -1.4599173482565675e-05, std 0.020016849040985107\n",
      "name: encoder.layers.6.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.6.attention.out_proj.weight, mean -1.8871585780289024e-05, std 0.02001277171075344\n",
      "name: encoder.layers.6.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.6.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.6.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.6.feed_forward.intermediate_dense.weight, mean 2.3277474610949866e-05, std 0.020003994926810265\n",
      "name: encoder.layers.6.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.6.feed_forward.output_dense.weight, mean -1.3764120012638159e-05, std 0.019998662173748016\n",
      "name: encoder.layers.6.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.6.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.6.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.7.attention.k_proj.weight, mean 1.1460921996331308e-05, std 0.020019633695483208\n",
      "name: encoder.layers.7.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.7.attention.v_proj.weight, mean 2.8963886506971903e-05, std 0.01996096596121788\n",
      "name: encoder.layers.7.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.7.attention.q_proj.weight, mean 2.716574090300128e-05, std 0.019982296973466873\n",
      "name: encoder.layers.7.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.7.attention.out_proj.weight, mean -3.403553273528814e-05, std 0.020036017522215843\n",
      "name: encoder.layers.7.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.7.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.7.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.7.feed_forward.intermediate_dense.weight, mean 6.70116719447833e-07, std 0.02001502923667431\n",
      "name: encoder.layers.7.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.7.feed_forward.output_dense.weight, mean 4.624300345312804e-06, std 0.019993551075458527\n",
      "name: encoder.layers.7.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.7.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.7.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.8.attention.k_proj.weight, mean -2.194212129325024e-06, std 0.019984442740678787\n",
      "name: encoder.layers.8.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.8.attention.v_proj.weight, mean -2.0062127532582963e-06, std 0.019954385235905647\n",
      "name: encoder.layers.8.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.8.attention.q_proj.weight, mean 1.2051499652443454e-05, std 0.020011652261018753\n",
      "name: encoder.layers.8.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.8.attention.out_proj.weight, mean -3.5922152164857835e-05, std 0.02000410109758377\n",
      "name: encoder.layers.8.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.8.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.8.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.8.feed_forward.intermediate_dense.weight, mean -1.6914186744543258e-06, std 0.01999736949801445\n",
      "name: encoder.layers.8.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.8.feed_forward.output_dense.weight, mean -7.12141229541885e-07, std 0.02000707946717739\n",
      "name: encoder.layers.8.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.8.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.8.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.9.attention.k_proj.weight, mean -2.0796016997337574e-06, std 0.020018132403492928\n",
      "name: encoder.layers.9.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.9.attention.v_proj.weight, mean -3.9545899198856205e-05, std 0.020005011931061745\n",
      "name: encoder.layers.9.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.9.attention.q_proj.weight, mean -1.4027535144123249e-05, std 0.01998085342347622\n",
      "name: encoder.layers.9.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.9.attention.out_proj.weight, mean 4.83102812722791e-05, std 0.02000616490840912\n",
      "name: encoder.layers.9.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.9.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.9.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.9.feed_forward.intermediate_dense.weight, mean -5.972398412268376e-06, std 0.020002026110887527\n",
      "name: encoder.layers.9.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.9.feed_forward.output_dense.weight, mean -1.8856047972803935e-05, std 0.020008984953165054\n",
      "name: encoder.layers.9.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.9.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.9.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.10.attention.k_proj.weight, mean -3.2998505048453808e-06, std 0.020005270838737488\n",
      "name: encoder.layers.10.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.10.attention.v_proj.weight, mean 1.3545891306421254e-05, std 0.02001049555838108\n",
      "name: encoder.layers.10.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.10.attention.q_proj.weight, mean -1.8830171029549092e-05, std 0.019971340894699097\n",
      "name: encoder.layers.10.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.10.attention.out_proj.weight, mean -4.0821305447025225e-05, std 0.02000979147851467\n",
      "name: encoder.layers.10.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.10.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.10.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.10.feed_forward.intermediate_dense.weight, mean -1.6561467418796383e-05, std 0.019989371299743652\n",
      "name: encoder.layers.10.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.10.feed_forward.output_dense.weight, mean -5.525362212210894e-06, std 0.01999773643910885\n",
      "name: encoder.layers.10.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.10.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.10.final_layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.11.attention.k_proj.weight, mean -4.472724685911089e-05, std 0.019983135163784027\n",
      "name: encoder.layers.11.attention.k_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.11.attention.v_proj.weight, mean -1.9420353055465966e-05, std 0.019999338313937187\n",
      "name: encoder.layers.11.attention.v_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.11.attention.q_proj.weight, mean 2.5973349693231285e-07, std 0.020028045400977135\n",
      "name: encoder.layers.11.attention.q_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.11.attention.out_proj.weight, mean 2.6678608264774084e-06, std 0.019984198734164238\n",
      "name: encoder.layers.11.attention.out_proj.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.11.layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.11.layer_norm.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.11.feed_forward.intermediate_dense.weight, mean -5.902873908780748e-06, std 0.01998891867697239\n",
      "name: encoder.layers.11.feed_forward.intermediate_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.11.feed_forward.output_dense.weight, mean 1.3053840120846871e-05, std 0.02000267058610916\n",
      "name: encoder.layers.11.feed_forward.output_dense.bias, mean 0.0, std 0.0\n",
      "name: encoder.layers.11.final_layer_norm.weight, mean 1.0, std 0.0\n",
      "name: encoder.layers.11.final_layer_norm.bias, mean 0.0, std 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import Wav2Vec2Config\n",
    "from seisLM.model.multidim_wav2vec2 import MultiDimWav2Vec2ForPreTraining\n",
    "import lightning\n",
    "\n",
    "lightning.seed_everything(42)\n",
    "model_name = \"patrickvonplaten/wav2vec2-base-v2\"\n",
    "config = Wav2Vec2Config.from_pretrained(model_name)\n",
    "model = MultiDimWav2Vec2ForPreTraining(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seisbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
