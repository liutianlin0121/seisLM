{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 17:03:55,736 | seisbench | WARNING | Component order not specified, defaulting to 'ZNE'.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"testing the multidim wav2vec model against the reference model\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "from lightning.pytorch import seed_everything\n",
    "import seisbench.data as sbd\n",
    "\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices, _sample_negative_indices\n",
    "from transformers import Wav2Vec2Config\n",
    "from transformers import Wav2Vec2ForPreTraining as RefWav2Vec2ForPreTraining\n",
    "from seisLM.model.multidim_wav2vec2 import MultiDimWav2Vec2ForPreTraining\n",
    "\n",
    "data = sbd.STEAD()\n",
    "waveforms = data.get_waveforms(1265656)\n",
    "input_values = torch.Tensor(waveforms).unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codevector_probs.shape torch.Size([2998, 320])\n",
      "codevector_probs.sum(0) tensor([11., 11.,  4.,  2.,  6.,  3.,  8.,  9., 14., 13.,  1.,  7.,  6.,  5.,\n",
      "         8.,  9.,  5.,  4.,  4.,  7.,  7., 15.,  4., 27.,  7.,  6., 17., 10.,\n",
      "        16.,  4.,  8.,  6., 17.,  6.,  8.,  2.,  3.,  2.,  4., 11., 13., 16.,\n",
      "         4.,  7.,  7.,  7.,  5., 10., 15., 12.,  3., 10., 10.,  4.,  9., 11.,\n",
      "        17.,  4., 15., 22., 41.,  5.,  9.,  7.,  9.,  4.,  4.,  1., 35.,  8.,\n",
      "         6.,  2., 16.,  6.,  9., 12., 11.,  4.,  5., 11.,  9.,  8.,  7., 13.,\n",
      "        12.,  6.,  9.,  4.,  9.,  2.,  4., 12., 12.,  4.,  5.,  9.,  9.,  2.,\n",
      "         4.,  5., 21.,  2., 33.,  2.,  1.,  9.,  8.,  6.,  9.,  8.,  4.,  7.,\n",
      "         6., 12.,  4.,  5., 11., 25.,  2.,  3., 20.,  8.,  5., 14.,  5., 12.,\n",
      "         7.,  4.,  3.,  5., 19.,  8., 43., 12.,  2., 18., 25.,  5., 14.,  6.,\n",
      "         3.,  4.,  6.,  5.,  4.,  7., 11., 29., 12., 11.,  5.,  5.,  6.,  6.,\n",
      "         4., 10., 21., 35., 20., 16., 12., 10.,  6.,  7.,  5., 19., 10.,  6.,\n",
      "         5.,  5.,  5.,  6.,  9.,  2., 25.,  3.,  7.,  4.,  2., 13.,  7., 25.,\n",
      "         6.,  5.,  2.,  4.,  4.,  3.,  4.,  5., 15., 33.,  1., 17., 17., 20.,\n",
      "         5.,  1., 10.,  6.,  9.,  8.,  7.,  7.,  3.,  4.,  6.,  5.,  3., 69.,\n",
      "         5.,  4., 16.,  4., 23.,  7., 15.,  5.,  3.,  8., 13., 54.,  5., 20.,\n",
      "         4.,  8.,  7.,  7.,  8.,  9.,  6.,  3.,  3., 18., 15.,  2.,  2., 16.,\n",
      "         5.,  4., 15.,  4.,  5.,  1.,  2., 13., 10.,  5.,  8.,  5.,  9., 10.,\n",
      "         6., 11., 12., 17.,  9.,  8.,  5., 17., 16.,  6., 19.,  7.,  2., 12.,\n",
      "         7., 14.,  5., 11.,  7.,  5., 11., 15.,  8.,  4.,  7.,  9.,  8.,  3.,\n",
      "        11.,  3.,  3.,  1.,  5.,  4.,  2.,  4.,  9., 10.,  4.,  8.,  3.,  5.,\n",
      "        13., 17.,  6.,  6., 16.,  4., 42.,  6., 11.,  8.,  5., 13., 46.,  5.,\n",
      "         8.,  3.,  4., 14.,  6.,  5.,  1.,  8., 17., 21., 15.,  6.])\n",
      "codevector_probs.sum(1) tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "tensor(182.2257)\n"
     ]
    }
   ],
   "source": [
    "model_output = {}\n",
    "# for model_name in MODEL_NAMES:\n",
    "config = Wav2Vec2Config.from_pretrained(\n",
    "  '/scicore/home/dokman0000/liu0003/projects/seisLM/seisLM/configs/pretrain/model_config_4xdownsample_sinkhorn.json'\n",
    ")\n",
    "\n",
    "\n",
    "# config.sinkhorn_quantization_iters = 1\n",
    "\n",
    "for sinkhorn_quantization_iter in [0, 1, 3, 5]:\n",
    "  print(f\"Sinkhorn quantization iter: {sinkhorn_quantization_iter}\")\n",
    "  config.sinkhorn_quantization_iters = sinkhorn_quantization_iter\n",
    "  model = MultiDimWav2Vec2ForPreTraining(config)\n",
    "\n",
    "  # compute masked indices\n",
    "  batch_size, num_channels, raw_sequence_length = input_values.shape\n",
    "  sequence_length = model._get_feat_extract_output_lengths(\n",
    "    raw_sequence_length).item()\n",
    "\n",
    "  seed_everything(0)\n",
    "  mask_time_indices = _compute_mask_indices(\n",
    "      shape=(batch_size, sequence_length), mask_prob=0.2, mask_length=2\n",
    "  )\n",
    "  sampled_negative_indices = _sample_negative_indices(\n",
    "      features_shape=(batch_size, sequence_length),\n",
    "      num_negatives=model.config.num_negatives,\n",
    "      mask_time_indices=mask_time_indices,\n",
    "  )\n",
    "  mask_time_indices = torch.tensor(\n",
    "    data=mask_time_indices, device=input_values.device, dtype=torch.long)\n",
    "  sampled_negative_indices = torch.tensor(\n",
    "    data=sampled_negative_indices, device=input_values.device,\n",
    "    dtype=torch.long\n",
    "  )\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(input_values, mask_time_indices=mask_time_indices,\n",
    "                    sampled_negative_indices=sampled_negative_indices)\n",
    "\n",
    "\n",
    "  print(outputs.codevector_perplexity)\n",
    "  # model_output[f'{model_name}_{model_type}'] = outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed set to 0\n",
    "# codevector_probs.shape torch.Size([2998, 320])\n",
    "# codevector_probs.sum(0) tensor([10., 10.,  7.,  8., 11.,  9.,  9., 11., 10., 11., 12., 10.,  9.,  8.,\n",
    "#          8.,  5.,  8.,  9., 10., 11., 10.,  9.,  9.,  7.,  8.,  9.,  7.,  8.,\n",
    "#         10., 10.,  9., 10., 10.,  8.,  8.,  8.,  9., 10., 11., 11., 11.,  8.,\n",
    "#         11.,  9.,  9., 10., 10.,  9., 10.,  7., 10.,  9.,  9., 11., 10.,  8.,\n",
    "#         11.,  9., 10.,  9., 12., 11.,  9.,  8.,  9., 10.,  7.,  8.,  8., 10.,\n",
    "#          9.,  9., 11., 10., 10.,  8., 11.,  8.,  6.,  9., 11.,  9., 10., 11.,\n",
    "#         11.,  8.,  8., 12.,  9., 11.,  9., 12., 11., 12.,  9.,  8., 10., 10.,\n",
    "#          9.,  8.,  8.,  7., 10.,  8.,  9.,  8.,  9.,  8.,  8., 13., 11.,  8.,\n",
    "#          8.,  9.,  9.,  8.,  9.,  9., 11., 10., 11.,  8., 11.,  9., 10., 10.,\n",
    "#          8., 10.,  6., 10., 10.,  6.,  9., 10.,  9.,  9.,  9.,  8., 13.,  9.,\n",
    "#         10.,  9., 12., 10.,  7.,  9., 10.,  8.,  8., 11., 10.,  9.,  9.,  8.,\n",
    "#         10., 10.,  7.,  6.,  9.,  5.,  8., 10., 10.,  8., 11.,  9., 10., 11.,\n",
    "#          7.,  8.,  9.,  9.,  6.,  8., 10., 10.,  9., 12.,  9.,  9., 10.,  7.,\n",
    "#          8., 10.,  8.,  9., 10.,  9., 12., 10., 12., 11.,  9., 10.,  9.,  9.,\n",
    "#         10., 12., 10., 10.,  9.,  9., 14., 10.,  9.,  8., 11., 10., 11.,  9.,\n",
    "#          9.,  8.,  9., 11., 11.,  8.,  9., 10.,  7., 10., 11., 10., 12., 11.,\n",
    "#         10.,  8.,  9., 10., 11.,  7.,  8.,  7., 11.,  9., 11.,  9., 10.,  9.,\n",
    "#          8.,  8.,  8., 12.,  9., 12., 12., 11., 10.,  8., 10., 10., 10.,  8.,\n",
    "#          9.,  8., 12., 12., 12.,  9.,  9.,  5.,  8.,  9., 11.,  9., 10., 10.,\n",
    "#          9., 11., 11.,  9.,  9.,  8., 10.,  9., 10.,  9.,  9.,  6.,  9.,  7.,\n",
    "#         10.,  8., 10.,  8.,  9.,  9., 11., 10., 11., 10.,  9.,  8.,  9., 10.,\n",
    "#         10., 10., 10.,  9.,  8., 14., 13.,  8., 10.,  9.,  8., 11.,  9.,  8.,\n",
    "#         10.,  9.,  8., 10.,  6., 10., 12.,  9., 10.,  8.,  8., 11.])\n",
    "# codevector_probs.sum(1) tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
    "# tensor(168.0099)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seisbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
