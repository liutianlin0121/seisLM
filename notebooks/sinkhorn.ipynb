{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 07:12:11,604 | seisbench | WARNING | Component order not specified, defaulting to 'ZNE'.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"testing the multidim wav2vec model against the reference model\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "from lightning.pytorch import seed_everything\n",
    "import seisbench.data as sbd\n",
    "\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices, _sample_negative_indices\n",
    "from transformers import Wav2Vec2Config\n",
    "from transformers import Wav2Vec2ForPreTraining as RefWav2Vec2ForPreTraining\n",
    "from seisLM.model.multidim_wav2vec2 import MultiDimWav2Vec2ForPreTraining\n",
    "\n",
    "data = sbd.STEAD()\n",
    "waveforms = data.get_waveforms(1265656)\n",
    "input_values = torch.Tensor(waveforms).unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Sinkhorn quantization iter: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L tensor([[  2.,   0.,   0.,   4.,   5.,   0.,   0.,   8.,   0.,   0.,   0.,   2.,\n",
      "          10.,   5.,   3.,   2.,   0.,   2.,   5.,   2.,   0.,   0.,   0.,   5.,\n",
      "           0.,   0.,   0.,   0.,   1.,   2.,   0.,   0.,  36.,   1.,   5.,   0.,\n",
      "           1.,  21.,   0.,   0.,   1.,   6.,   0.,   0.,   0.,   4.,  12.,   0.,\n",
      "           5.,   2.,   0.,   1.,   1.,   0.,   0.,   0.,   0.,   5.,  11.,   7.,\n",
      "           6.,   0.,  13.,   0.,   0.,   1.,   1.,   3.,  10.,   0.,   0.,   3.,\n",
      "          22.,   7.,   0.,   1.,   5.,   1.,   8.,   2.,  16.,   0.,   1.,  20.,\n",
      "          13.,   0.,   0.,   3.,   1.,   0.,   0.,   5.,   5.,   2.,   0.,   1.,\n",
      "           0.,   2.,   2.,   2.,   0.,   6.,  12.,   0.,   0.,   0.,   5.,   0.,\n",
      "           6.,   4.,   0.,   0.,   7.,   1.,   1.,   1.,   6.,  10.,   0.,   0.,\n",
      "           0.,  19.,   4.,   0.,   0.,   4.,   0.,   0.,  50.,   1.,   1.,   0.,\n",
      "           0.,   1.,   2.,  13.,   5.,   5.,   0.,  17.,   0.,   1.,   1.,   0.,\n",
      "           0.,   3.,   0.,   0.,   0.,  15., 164.,   8.,  11., 169.,   0.,   2.,\n",
      "          14.,   8.,   0.,   3.,   3.,   0.,   0.,   7.,  25.,   0.,   3.,   1.,\n",
      "           0.,   1.,   0.,   0.,   0.,   0.,   3.,   5.,   0.,   8.,  62.,   0.,\n",
      "           5.,   3.,   7.,   1.,   1.,   0.,   2.,   2.,   2.,   8.,   0.,  19.,\n",
      "           0.,   0.,   3.,  16.,   0.,  12.,   0.,   2.,   4.,   0.,   0.,   0.,\n",
      "           0.,   3.,   5.,   0.,  22.,   0.,   0.,   0.,   1.,   2.,   0.,   1.,\n",
      "           6.,   2.,   1.,   4.,   0.,   1.,   6.,  10.,   0.,   0.,   1.,   0.,\n",
      "          22.,  25.,   0.,   1.,   2.,  27.,   8.,   0.,   1.,   1.,   2.,   4.,\n",
      "          13.,   0.,  20.,   1.,   4.,   2.,   0.,   2.,   0.,   0.,   1.,  52.,\n",
      "           3.,   0.,   0.,   3.,   1.,   1.,   1.,   6.,   7.,   4.,   0.,   4.,\n",
      "           0.,   7.,   0.,   0.,   0.,   0.,   1.,   6.,   0.,   1.,   2.,   0.,\n",
      "           0.,   0.,   4.,   4.,   0.,   0.,   0.,   0.,   1.,   0.,   2.,   1.,\n",
      "           0.,   0.,   2.,   0.,   1.,   0.,   9.,   1.,   4.,   5.,   6.,   2.,\n",
      "           0.,   0.,   3.,   3.,   0.,   0.,   0.,   1.,   2.,   0.,   0.,   5.,\n",
      "           5.,   7.,   0.,   4.,   0.,   0.,   1.,   8.],\n",
      "        [  0.,   8.,   0.,   2.,   2.,   0.,  64.,   8.,   0.,   3.,   2.,   0.,\n",
      "           1.,   1.,   6.,   2.,   0.,   3.,   0.,   8.,   0.,   8.,   9.,   1.,\n",
      "           0.,   1.,   5.,   0.,   1.,  14.,   1.,  55.,   1.,   0.,   0.,   0.,\n",
      "           7.,   0.,   0.,   2.,   1.,   7.,  12.,   0.,   5.,   0.,  29.,  23.,\n",
      "          28.,  13.,   9.,   0.,   6.,   0.,   4.,   1.,   0.,  25.,   0.,  10.,\n",
      "           4.,  10.,   4.,   0.,   0.,   1.,  12.,   0.,   7.,   1.,  26.,  25.,\n",
      "           0.,   0.,   8.,   3.,   0.,   3.,   3.,   0.,   1.,   0.,  10.,   3.,\n",
      "           8.,   1.,  12.,   6.,   0.,   0.,   1.,   5.,  13.,   0.,   3.,   6.,\n",
      "           0.,   0.,   2.,   2.,   2.,   3.,   0.,   0.,   1.,   6.,   1.,   6.,\n",
      "           1.,   0.,   0.,   1.,   3.,   2.,   0.,   0.,   3.,   0.,   7.,   9.,\n",
      "          51.,  19.,   3.,   7.,   1.,   0.,   0.,   1.,   5.,   2.,   0.,   0.,\n",
      "           0.,   2.,   1.,   0.,   0.,   9.,   0.,   6.,   3.,   0.,   0.,   1.,\n",
      "           0.,   2.,   0.,   0.,  11.,   0.,   1.,   0.,   1.,   2.,   0.,   5.,\n",
      "           0.,   5.,   0.,   0.,   0.,   0.,   0.,  12.,   1.,   1.,   3.,   1.,\n",
      "          16.,   0.,   4.,   8.,   5.,   0.,   0.,  14.,   1.,   0.,  29.,   0.,\n",
      "          48.,   6.,   1.,   2.,   0.,   4.,  11.,  12.,   0.,   8.,   0.,   1.,\n",
      "           4.,   0.,   0.,   0.,   4.,   3.,   4.,   4.,   0.,   1.,   0.,   0.,\n",
      "          11.,   1.,   1.,   3.,   0.,   9.,   0.,   0.,   3.,   0.,   6.,   0.,\n",
      "           0.,   0.,   3.,   5.,   0.,   4.,   2.,   3.,   0.,   5.,   3.,   4.,\n",
      "           1.,   4.,   0.,   0.,   0.,   7.,   3.,   0.,   0.,   0.,   1.,   0.,\n",
      "           0.,   0.,   1.,   9.,   3.,   2.,   0.,   2.,   0.,   0.,   4.,   0.,\n",
      "          44.,   0.,   0.,   4.,   0.,   0.,   0.,   0.,   5.,   0.,   0.,   0.,\n",
      "          20.,  26.,   8.,   1.,   2.,   0.,   7.,  47.,   0.,   8.,   1.,  12.,\n",
      "           0.,   5.,   0.,   2.,   9.,   0.,   2.,   7.,   7.,   3.,   4.,   9.,\n",
      "           0.,   3.,   8.,   2.,   4.,   7.,  19.,   0.,   1.,   0.,   8.,   1.,\n",
      "           4.,   3.,  13.,   0.,   0.,   4.,   6.,   3.,   0.,   1.,   0.,   0.,\n",
      "           5.,  87.,   0.,  20.,   0.,   8.,   0.,   0.]])\n",
      "codevector_probs over V tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        ...,\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor(148.3567)\n",
      "------------\n",
      "Sinkhorn quantization iter: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L tensor([[10.,  9.,  3.,  1.,  2.,  2.,  1.,  4., 11., 10.,  0.,  3.,  1.,  2.,\n",
      "          4.,  2.,  3.,  2.,  3.,  2.,  3.,  4.,  1., 23.,  2.,  2., 13.,  8.,\n",
      "          7.,  7.,  3.,  0., 14.,  6.,  6.,  3.,  2.,  2.,  1.,  4.,  7., 13.,\n",
      "          3.,  2.,  2.,  3.,  0.,  8.,  4.,  5.,  2.,  2.,  7.,  2.,  5.,  4.,\n",
      "          7.,  3., 10.,  4.,  6.,  3.,  3.,  2.,  1.,  4.,  3.,  1., 25.,  1.,\n",
      "          2.,  2.,  3.,  2.,  3.,  5.,  5.,  1.,  3.,  2.,  2.,  5.,  3.,  4.,\n",
      "          8.,  4.,  5.,  4.,  5.,  1.,  2.,  3.,  4.,  2.,  1.,  2.,  8.,  4.,\n",
      "          4.,  3.,  2.,  0.,  6.,  2.,  2.,  3.,  7.,  1.,  1.,  2.,  1.,  1.,\n",
      "          1.,  6.,  3.,  2.,  9., 17.,  2.,  3., 11.,  4.,  2., 10.,  4.,  1.,\n",
      "          5.,  2.,  5.,  1., 16.,  4.,  1., 10.,  2., 10., 12.,  3.,  3.,  3.,\n",
      "          1.,  3.,  2.,  5.,  1.,  5.,  8., 10., 10.,  6.,  1.,  2.,  5.,  2.,\n",
      "          1.,  3., 11., 27., 16.,  3.,  5.,  4.,  3.,  2.,  1., 17.,  6.,  3.,\n",
      "          3.,  4.,  2.,  3.,  7.,  2., 11.,  2.,  2.,  1.,  4.,  5.,  1., 13.,\n",
      "          2.,  3.,  2.,  2.,  3.,  1.,  3.,  3., 10.,  6.,  4.,  8., 13., 15.,\n",
      "          2.,  4.,  5.,  4.,  4.,  1.,  4.,  6.,  0.,  3.,  3.,  2.,  2., 54.,\n",
      "          1.,  2.,  3.,  3., 15.,  3.,  7.,  2.,  1.,  6.,  6.,  3.,  2.,  4.,\n",
      "          3.,  4.,  1.,  5.,  6.,  2.,  2.,  3.,  3., 15., 10.,  2.,  2., 11.,\n",
      "          1.,  1.,  9.,  4.,  3.,  1.,  2.,  7.,  4.,  2.,  4.,  2.,  4.,  7.,\n",
      "          1.,  6.,  3., 12.,  6.,  2.,  2.,  6., 11.,  3., 11.,  4.,  1.,  8.,\n",
      "          5.,  5.,  3.,  3.,  5.,  2.,  8., 11.,  5.,  1.,  3.,  4.,  2.,  1.,\n",
      "          1.,  2.,  2.,  1.,  1.,  1.,  2.,  4.,  7.,  9.,  3.,  5.,  1.,  3.,\n",
      "          3.,  3.,  2.,  2., 10.,  2.,  3.,  3.,  2.,  2.,  2.,  2., 38.,  3.,\n",
      "          4.,  2.,  4.,  6.,  3.,  2.,  1.,  5., 11., 13., 11.,  4.],\n",
      "        [ 1.,  1.,  3.,  3.,  5.,  2.,  6.,  4.,  6.,  1.,  1.,  4.,  5.,  5.,\n",
      "          5.,  7.,  4.,  2.,  3.,  5.,  5., 12.,  3.,  6.,  5.,  4.,  3.,  1.,\n",
      "          9.,  2.,  6.,  2.,  1.,  1.,  2.,  1.,  3.,  2.,  3., 10.,  1.,  1.,\n",
      "          3.,  5.,  2.,  6.,  3.,  2., 11.,  6.,  1.,  7., 10.,  1.,  6.,  8.,\n",
      "          1.,  0.,  5., 14., 36.,  2.,  9.,  5.,  7.,  2.,  2.,  1.,  4.,  5.,\n",
      "          6.,  2., 14.,  6.,  5.,  7.,  1.,  2.,  1.,  4.,  5.,  5.,  6.,  7.,\n",
      "          5.,  4.,  1.,  2.,  3.,  2.,  1.,  9.,  9.,  2.,  3.,  5.,  5.,  1.,\n",
      "          2.,  4., 14.,  2., 25.,  1.,  1.,  6.,  2.,  5.,  7.,  8.,  4.,  5.,\n",
      "          4.,  6.,  3.,  4.,  2.,  3.,  1.,  2.,  4.,  3.,  3.,  2.,  1., 10.,\n",
      "          3.,  1.,  2.,  3.,  6.,  1., 35.,  2.,  2.,  4., 10.,  5., 11.,  3.,\n",
      "          2.,  2.,  5.,  1.,  2.,  2.,  3., 24.,  3.,  8.,  4.,  2.,  4.,  3.,\n",
      "          4.,  7., 12.,  9.,  4., 11.,  7.,  7.,  3.,  4.,  3.,  0.,  4.,  4.,\n",
      "          3.,  2.,  2.,  4.,  3.,  4., 13.,  1.,  4.,  2.,  2., 10.,  5.,  8.,\n",
      "          6.,  2.,  1.,  4.,  2.,  2.,  3.,  2.,  7., 25.,  1.,  9.,  3.,  6.,\n",
      "          2.,  1.,  6.,  4.,  4.,  3.,  6.,  2.,  1.,  3.,  1.,  3.,  1.,  2.,\n",
      "          3.,  3., 13.,  0.,  8.,  0.,  9.,  4.,  2.,  3.,  2., 47.,  1., 12.,\n",
      "          3.,  2.,  5.,  2.,  1.,  8.,  2.,  0.,  5.,  4.,  3.,  5.,  1.,  5.,\n",
      "          4.,  2.,  6.,  3.,  5.,  1.,  2.,  6.,  6.,  3.,  1.,  4.,  5.,  2.,\n",
      "          4.,  6.,  8.,  2.,  3.,  6.,  2., 10.,  5.,  3.,  6.,  3.,  1.,  2.,\n",
      "          1., 12.,  1.,  6.,  6.,  2.,  1.,  4.,  4.,  3.,  5.,  6.,  5.,  3.,\n",
      "          7.,  2.,  1.,  3.,  1.,  2.,  3.,  2.,  3.,  3.,  3.,  4.,  4.,  3.,\n",
      "         11., 15.,  4.,  2.,  5.,  3., 34.,  5.,  7.,  4.,  2.,  9.,  3.,  2.,\n",
      "          3.,  1.,  2., 11.,  3.,  3.,  5.,  2.,  2.,  8.,  2.,  3.]])\n",
      "codevector_probs over V tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        ...,\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor(182.2257)\n",
      "------------\n",
      "Sinkhorn quantization iter: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L tensor([[ 6.,  7.,  4.,  6.,  4.,  6.,  3.,  4.,  8.,  7.,  5.,  4.,  3.,  3.,\n",
      "          5.,  3.,  5.,  3.,  4.,  3.,  3.,  5.,  7., 12.,  3.,  2.,  7.,  6.,\n",
      "          6.,  5.,  4.,  5.,  7.,  7.,  5.,  4.,  3.,  3.,  4.,  6.,  5., 10.,\n",
      "          4.,  4.,  5.,  3.,  3.,  5.,  4.,  5.,  6.,  4.,  6.,  4.,  6.,  5.,\n",
      "          7.,  7.,  7.,  4.,  4.,  3.,  5.,  2.,  1.,  5.,  3.,  5.,  8.,  2.,\n",
      "          3.,  4.,  6.,  4.,  2.,  5.,  5.,  4.,  3.,  4.,  2.,  5.,  6.,  4.,\n",
      "          5.,  6.,  7.,  5.,  5.,  4.,  2.,  3.,  4.,  4.,  4.,  5.,  5.,  4.,\n",
      "          5.,  3.,  4.,  1.,  4.,  3.,  4.,  3.,  7.,  2.,  4.,  7.,  3.,  5.,\n",
      "          6.,  4.,  4.,  7.,  7., 11.,  2.,  4.,  7.,  3.,  4.,  4.,  7.,  3.,\n",
      "          6.,  5.,  5.,  3., 10.,  4.,  3.,  4.,  3.,  5.,  8.,  3.,  6.,  3.,\n",
      "          3.,  6.,  3.,  6.,  1.,  4.,  7.,  6.,  8.,  5.,  4.,  2.,  4.,  4.,\n",
      "          2.,  5.,  3.,  8.,  7.,  5.,  5.,  6.,  4.,  3.,  3.,  8.,  6.,  4.,\n",
      "          5.,  6.,  5.,  5.,  6.,  3.,  5.,  3.,  3.,  2.,  7.,  6.,  4.,  9.,\n",
      "          3.,  5.,  3.,  3.,  4.,  1.,  6.,  5.,  8.,  5.,  4.,  7.,  7.,  7.,\n",
      "          2.,  6.,  5.,  5.,  6.,  2.,  4.,  5.,  3.,  4.,  4.,  4.,  4., 14.,\n",
      "          3.,  3.,  4.,  4.,  7.,  6.,  5.,  4.,  3.,  5.,  6.,  4.,  7.,  4.,\n",
      "          4.,  6.,  3.,  4.,  6.,  3.,  3.,  3.,  7.,  8.,  6.,  2.,  3.,  7.,\n",
      "          3.,  3.,  8.,  3.,  5.,  3.,  4.,  5.,  4.,  5.,  5.,  4.,  5.,  6.,\n",
      "          1.,  5.,  3.,  4.,  6.,  3.,  4.,  5.,  9.,  6.,  9.,  4.,  4.,  6.,\n",
      "          6.,  4.,  4.,  5.,  5.,  2.,  5.,  9.,  4.,  3.,  6.,  4.,  5.,  2.,\n",
      "          2.,  3.,  4.,  4.,  2.,  2.,  4.,  5.,  4.,  6.,  5.,  6.,  3.,  4.,\n",
      "          4.,  5.,  4.,  6.,  7.,  4.,  4.,  4.,  2.,  3.,  4.,  3., 12.,  6.,\n",
      "          5.,  4.,  4.,  3.,  4.,  4.,  5.,  5.,  7.,  8.,  6.,  4.],\n",
      "        [ 5.,  2.,  4.,  4.,  5.,  4.,  6.,  5.,  4.,  3.,  3.,  4.,  5.,  4.,\n",
      "          4.,  6.,  6.,  4.,  3.,  6.,  5.,  6.,  4.,  4.,  5.,  4.,  3.,  3.,\n",
      "          6.,  3.,  4.,  3.,  5.,  2.,  3.,  3.,  5.,  4.,  6.,  8.,  3.,  3.,\n",
      "          5.,  5.,  5.,  5.,  5.,  4.,  7.,  6.,  4.,  5.,  8.,  4.,  6.,  4.,\n",
      "          2.,  3.,  6., 12.,  6.,  5.,  5.,  5.,  6.,  3.,  3.,  2.,  4.,  7.,\n",
      "          5.,  6.,  8.,  4.,  7.,  6.,  2.,  5.,  2.,  5.,  5.,  5.,  5.,  7.,\n",
      "          6.,  3.,  4.,  2.,  4.,  3.,  6.,  4.,  8.,  4.,  4.,  3.,  6.,  3.,\n",
      "          4.,  6.,  9.,  6., 11.,  2.,  3.,  4.,  3.,  5.,  4.,  6.,  4.,  4.,\n",
      "          4.,  6.,  4.,  6.,  5.,  4.,  3.,  5.,  5.,  5.,  4.,  2.,  6.,  8.,\n",
      "          3.,  3.,  5.,  3.,  5.,  5., 10.,  4.,  3.,  4.,  6.,  5.,  6.,  4.,\n",
      "          4.,  3.,  5.,  2.,  3.,  3.,  5., 10.,  4.,  7.,  6.,  4.,  5.,  3.,\n",
      "          5.,  5., 10.,  6.,  4.,  8.,  6.,  6.,  3.,  6.,  4.,  4.,  3.,  4.,\n",
      "          4.,  4.,  5.,  4.,  3.,  5.,  6.,  2.,  5.,  3.,  4.,  6.,  5.,  5.,\n",
      "          5.,  6.,  2.,  5.,  4.,  3.,  4.,  4.,  5.,  9.,  4.,  6.,  5.,  6.,\n",
      "          2.,  5.,  8.,  4.,  5.,  3.,  7.,  4.,  4.,  4.,  2.,  3.,  3.,  4.,\n",
      "          2.,  4.,  8.,  4.,  6.,  4.,  5.,  8.,  5.,  5.,  4., 18.,  3.,  7.,\n",
      "          5.,  4.,  6.,  3.,  4.,  5.,  3.,  4.,  4.,  4.,  4.,  5.,  3.,  7.,\n",
      "          4.,  2.,  5.,  5.,  5.,  3.,  4.,  6.,  6.,  3.,  1.,  4.,  5.,  4.,\n",
      "          4.,  5.,  5.,  4.,  5.,  4.,  5.,  7.,  7.,  4.,  5.,  7.,  2.,  4.,\n",
      "          3.,  5.,  3., 10.,  8.,  2.,  3.,  5.,  5.,  6.,  5.,  6.,  6.,  4.,\n",
      "          7.,  5.,  2.,  4.,  1.,  3.,  5.,  2.,  4.,  5.,  5.,  4.,  4.,  3.,\n",
      "          5.,  7.,  6.,  4.,  3.,  4., 10.,  6.,  6.,  3.,  3.,  5.,  5.,  3.,\n",
      "          3.,  2.,  6.,  9.,  3.,  4.,  5.,  4.,  4.,  5.,  4.,  4.]])\n",
      "codevector_probs over V tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        ...,\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor(182.2257)\n",
      "------------\n",
      "Sinkhorn quantization iter: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L tensor([[ 5.,  5.,  5.,  6.,  4.,  5.,  5.,  3.,  7.,  7.,  5.,  4.,  4.,  4.,\n",
      "          6.,  4.,  6.,  5.,  4.,  3.,  4.,  5.,  7., 10.,  6.,  5.,  5.,  5.,\n",
      "          5.,  4.,  5.,  5.,  6.,  6.,  5.,  5.,  3.,  4.,  3.,  7.,  5.,  8.,\n",
      "          5.,  3.,  5.,  5.,  3.,  6.,  5.,  4.,  6.,  4.,  4.,  4.,  6.,  6.,\n",
      "          5.,  5.,  7.,  5.,  6.,  4.,  4.,  3.,  3.,  5.,  3.,  6.,  7.,  3.,\n",
      "          4.,  4.,  6.,  4.,  4.,  5.,  5.,  4.,  4.,  4.,  2.,  5.,  6.,  5.,\n",
      "          5.,  5.,  7.,  6.,  5.,  3.,  2.,  3.,  4.,  5.,  2.,  5.,  5.,  4.,\n",
      "          5.,  3.,  4.,  3.,  5.,  4.,  4.,  3.,  5.,  3.,  5.,  6.,  4.,  5.,\n",
      "          5.,  3.,  4.,  6.,  6.,  5.,  3.,  5.,  4.,  3.,  4.,  5.,  6.,  4.,\n",
      "          5.,  4.,  4.,  4.,  9.,  5.,  4.,  4.,  4.,  4.,  7.,  4.,  6.,  4.,\n",
      "          3.,  6.,  3.,  5.,  2.,  4.,  6.,  6.,  6.,  6.,  3.,  4.,  3.,  5.,\n",
      "          5.,  5.,  2.,  5.,  6.,  5.,  5.,  7.,  5.,  3.,  4.,  6.,  5.,  6.,\n",
      "          5.,  6.,  5.,  6.,  6.,  3.,  4.,  3.,  3.,  3.,  7.,  6.,  6.,  6.,\n",
      "          3.,  5.,  6.,  5.,  4.,  4.,  3.,  4.,  5.,  5.,  6.,  6.,  5.,  6.,\n",
      "          2.,  6.,  5.,  5.,  5.,  4.,  4.,  5.,  4.,  4.,  4.,  4.,  6.,  8.,\n",
      "          5.,  6.,  3.,  4.,  5.,  6.,  5.,  4.,  3.,  5.,  4.,  4.,  7.,  5.,\n",
      "          4.,  5.,  3.,  4.,  7.,  3.,  3.,  4.,  5.,  7.,  6.,  2.,  3.,  5.,\n",
      "          4.,  3.,  6.,  3.,  6.,  3.,  5.,  4.,  5.,  5.,  6.,  4.,  6.,  6.,\n",
      "          4.,  6.,  3.,  4.,  5.,  4.,  5.,  3.,  5.,  6.,  7.,  5.,  5.,  6.,\n",
      "          6.,  5.,  4.,  6.,  5.,  2.,  6.,  7.,  4.,  3.,  6.,  4.,  3.,  2.,\n",
      "          1.,  4.,  4.,  6.,  4.,  3.,  4.,  5.,  3.,  6.,  6.,  6.,  5.,  4.,\n",
      "          4.,  5.,  4.,  5.,  6.,  5.,  6.,  4.,  3.,  4.,  4.,  4.,  5.,  5.,\n",
      "          5.,  4.,  4.,  4.,  4.,  4.,  5.,  5.,  7.,  6.,  5.,  4.],\n",
      "        [ 5.,  3.,  5.,  5.,  5.,  4.,  5.,  5.,  3.,  4.,  5.,  5.,  4.,  5.,\n",
      "          5.,  5.,  6.,  4.,  4.,  6.,  5.,  4.,  5.,  5.,  5.,  4.,  3.,  5.,\n",
      "          6.,  3.,  5.,  5.,  5.,  3.,  5.,  3.,  4.,  3.,  5.,  7.,  4.,  2.,\n",
      "          6.,  5.,  5.,  4.,  5.,  3.,  6.,  5.,  5.,  4.,  8.,  4.,  6.,  3.,\n",
      "          3.,  5.,  6.,  5.,  5.,  5.,  5.,  5.,  5.,  3.,  3.,  4.,  4.,  6.,\n",
      "          5.,  6.,  5.,  4.,  6.,  6.,  3.,  5.,  3.,  5.,  5.,  6.,  5.,  6.,\n",
      "          6.,  4.,  6.,  4.,  4.,  3.,  7.,  4.,  5.,  4.,  4.,  3.,  6.,  2.,\n",
      "          5.,  6.,  8.,  4.,  5.,  3.,  6.,  4.,  4.,  5.,  4.,  5.,  4.,  5.,\n",
      "          5.,  7.,  4.,  5.,  5.,  5.,  3.,  4.,  5.,  6.,  5.,  2.,  5.,  5.,\n",
      "          4.,  3.,  5.,  3.,  6.,  5.,  6.,  5.,  5.,  4.,  5.,  5.,  6.,  4.,\n",
      "          5.,  4.,  5.,  3.,  4.,  4.,  5.,  6.,  4.,  7.,  6.,  4.,  5.,  5.,\n",
      "          6.,  4.,  7.,  5.,  4.,  8.,  6.,  4.,  4.,  5.,  4.,  5.,  3.,  4.,\n",
      "          4.,  3.,  5.,  5.,  5.,  5.,  4.,  4.,  5.,  4.,  3.,  6.,  5.,  5.,\n",
      "          5.,  4.,  3.,  5.,  6.,  3.,  4.,  4.,  4.,  7.,  4.,  5.,  5.,  6.,\n",
      "          2.,  4.,  8.,  3.,  5.,  2.,  7.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
      "          2.,  4.,  6.,  4.,  4.,  4.,  4.,  9.,  7.,  5.,  5.,  9.,  3.,  7.,\n",
      "          4.,  5.,  6.,  3.,  5.,  4.,  2.,  4.,  4.,  6.,  4.,  6.,  3.,  7.,\n",
      "          5.,  3.,  4.,  5.,  5.,  4.,  7.,  6.,  6.,  4.,  2.,  5.,  4.,  4.,\n",
      "          5.,  4.,  5.,  5.,  6.,  4.,  6.,  6.,  5.,  4.,  5.,  6.,  5.,  5.,\n",
      "          4.,  5.,  4.,  8.,  6.,  4.,  3.,  5.,  5.,  6.,  4.,  5.,  6.,  5.,\n",
      "          4.,  5.,  4.,  6.,  4.,  3.,  5.,  3.,  5.,  5.,  4.,  4.,  5.,  3.,\n",
      "          4.,  5.,  6.,  5.,  3.,  5.,  6.,  6.,  5.,  3.,  4.,  5.,  5.,  3.,\n",
      "          5.,  3.,  5.,  7.,  5.,  5.,  5.,  4.,  5.,  4.,  4.,  4.]])\n",
      "codevector_probs over V tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        ...,\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor(182.2257)\n"
     ]
    }
   ],
   "source": [
    "model_output = {}\n",
    "# for model_name in MODEL_NAMES:\n",
    "config = Wav2Vec2Config.from_pretrained(\n",
    "  '/scicore/home/dokman0000/liu0003/projects/seisLM/seisLM/configs/pretrain/model_config_4xdownsample_sinkhorn.json'\n",
    ")\n",
    "\n",
    "\n",
    "# config.sinkhorn_quantization_iters = 1\n",
    "\n",
    "for sinkhorn_quantization_iter in [0, 1, 3, 5]:\n",
    "  print('------------')\n",
    "  print(f\"Sinkhorn quantization iter: {sinkhorn_quantization_iter}\")\n",
    "  config.sinkhorn_quantization_iters = sinkhorn_quantization_iter\n",
    "  model = MultiDimWav2Vec2ForPreTraining(config)\n",
    "\n",
    "  # compute masked indices\n",
    "  batch_size, num_channels, raw_sequence_length = input_values.shape\n",
    "  sequence_length = model._get_feat_extract_output_lengths(\n",
    "    raw_sequence_length).item()\n",
    "\n",
    "  seed_everything(0)\n",
    "  mask_time_indices = _compute_mask_indices(\n",
    "      shape=(batch_size, sequence_length), mask_prob=0.2, mask_length=2\n",
    "  )\n",
    "  sampled_negative_indices = _sample_negative_indices(\n",
    "      features_shape=(batch_size, sequence_length),\n",
    "      num_negatives=model.config.num_negatives,\n",
    "      mask_time_indices=mask_time_indices,\n",
    "  )\n",
    "  mask_time_indices = torch.tensor(\n",
    "    data=mask_time_indices, device=input_values.device, dtype=torch.long)\n",
    "  sampled_negative_indices = torch.tensor(\n",
    "    data=sampled_negative_indices, device=input_values.device,\n",
    "    dtype=torch.long\n",
    "  )\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(input_values, mask_time_indices=mask_time_indices,\n",
    "                    sampled_negative_indices=sampled_negative_indices)\n",
    "\n",
    "\n",
    "  print(outputs.codevector_perplexity)\n",
    "  # model_output[f'{model_name}_{model_type}'] = outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed set to 0\n",
    "# codevector_probs.shape torch.Size([2998, 320])\n",
    "# codevector_probs.sum(0) tensor([10., 10.,  7.,  8., 11.,  9.,  9., 11., 10., 11., 12., 10.,  9.,  8.,\n",
    "#          8.,  5.,  8.,  9., 10., 11., 10.,  9.,  9.,  7.,  8.,  9.,  7.,  8.,\n",
    "#         10., 10.,  9., 10., 10.,  8.,  8.,  8.,  9., 10., 11., 11., 11.,  8.,\n",
    "#         11.,  9.,  9., 10., 10.,  9., 10.,  7., 10.,  9.,  9., 11., 10.,  8.,\n",
    "#         11.,  9., 10.,  9., 12., 11.,  9.,  8.,  9., 10.,  7.,  8.,  8., 10.,\n",
    "#          9.,  9., 11., 10., 10.,  8., 11.,  8.,  6.,  9., 11.,  9., 10., 11.,\n",
    "#         11.,  8.,  8., 12.,  9., 11.,  9., 12., 11., 12.,  9.,  8., 10., 10.,\n",
    "#          9.,  8.,  8.,  7., 10.,  8.,  9.,  8.,  9.,  8.,  8., 13., 11.,  8.,\n",
    "#          8.,  9.,  9.,  8.,  9.,  9., 11., 10., 11.,  8., 11.,  9., 10., 10.,\n",
    "#          8., 10.,  6., 10., 10.,  6.,  9., 10.,  9.,  9.,  9.,  8., 13.,  9.,\n",
    "#         10.,  9., 12., 10.,  7.,  9., 10.,  8.,  8., 11., 10.,  9.,  9.,  8.,\n",
    "#         10., 10.,  7.,  6.,  9.,  5.,  8., 10., 10.,  8., 11.,  9., 10., 11.,\n",
    "#          7.,  8.,  9.,  9.,  6.,  8., 10., 10.,  9., 12.,  9.,  9., 10.,  7.,\n",
    "#          8., 10.,  8.,  9., 10.,  9., 12., 10., 12., 11.,  9., 10.,  9.,  9.,\n",
    "#         10., 12., 10., 10.,  9.,  9., 14., 10.,  9.,  8., 11., 10., 11.,  9.,\n",
    "#          9.,  8.,  9., 11., 11.,  8.,  9., 10.,  7., 10., 11., 10., 12., 11.,\n",
    "#         10.,  8.,  9., 10., 11.,  7.,  8.,  7., 11.,  9., 11.,  9., 10.,  9.,\n",
    "#          8.,  8.,  8., 12.,  9., 12., 12., 11., 10.,  8., 10., 10., 10.,  8.,\n",
    "#          9.,  8., 12., 12., 12.,  9.,  9.,  5.,  8.,  9., 11.,  9., 10., 10.,\n",
    "#          9., 11., 11.,  9.,  9.,  8., 10.,  9., 10.,  9.,  9.,  6.,  9.,  7.,\n",
    "#         10.,  8., 10.,  8.,  9.,  9., 11., 10., 11., 10.,  9.,  8.,  9., 10.,\n",
    "#         10., 10., 10.,  9.,  8., 14., 13.,  8., 10.,  9.,  8., 11.,  9.,  8.,\n",
    "#         10.,  9.,  8., 10.,  6., 10., 12.,  9., 10.,  8.,  8., 11.])\n",
    "# codevector_probs.sum(1) tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
    "# tensor(168.0099)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seisbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
