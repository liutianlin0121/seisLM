{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 19:15:59,698 | seisbench | WARNING | Component order not specified, defaulting to 'ZNE'.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"testing the multidim wav2vec model against the reference model\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "from lightning.pytorch import seed_everything\n",
    "import seisbench.data as sbd\n",
    "\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices, _sample_negative_indices\n",
    "from transformers import Wav2Vec2Config\n",
    "from transformers import Wav2Vec2ForPreTraining as RefWav2Vec2ForPreTraining\n",
    "from seisLM.model.multidim_wav2vec2 import MultiDimWav2Vec2ForPreTraining\n",
    "\n",
    "data = sbd.STEAD()\n",
    "waveforms = data.get_waveforms(1265656)\n",
    "input_values = torch.Tensor(waveforms).unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Sinkhorn quantization iter: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states.std: 0.9999865889549255\n",
      "weight_proj.std: 0.9989061951637268\n",
      "hidden_states.std after weight_proj: 15.974702835083008\n",
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L [[  0   0   5   0   8   0   0   7  10   3   0   0   6   8   0   1   1   1\n",
      "    1   3   0   0  12   0   1   3  17   0   0   0   1   0   2   2   0   1\n",
      "    0   0   3  26   5   0   0   8  12  16   4   0   2   0  10   4   2   0\n",
      "    0   0  19   0   0   5  10   0   0   2   0  15   0   0   0   0   5   0\n",
      "    1   0   0   0   0   0   1  13   0   0   0   2   0   1   0   0   5  19\n",
      "    6   5   0   4 258   0   3   0   2   0   1   1   1 128   8   0   0   0\n",
      "    2   8   0   0   0   1   0   0   3   4   3   0   1   1   9   9   9   0\n",
      "    1   0   0   0   0   3   0   0   1   0   0   3  13   0   0   0   0   0\n",
      "    7   0  18   6   3   2   1   4   0   0   5   2   0   2   0   2  12  14\n",
      "    0   4   0   2   4   3   1   1   4   1   0   0   3   0   4   0   2   0\n",
      "    0   0   1   5   1  10   0   0   3   0   1   2   0   0   2   5   0   0\n",
      "    0   0   1   0   0  15   4  13   1   2  16   0  13   3   3  15   0   8\n",
      "    0   1   2   0   0   0   5  10   3   5   1   4   0  98   9   0   2  26\n",
      "    7   3   0   0   1   1  11   1   0  30   1   4   2   5   0   3   1   0\n",
      "    2  13   1   0   0   0   4   0   0   0   0   2   9  21   6   0   0   0\n",
      "   21   2  21   0   0   0   0   0   0   1   0   7  42   0   1   0   2   2\n",
      "    0   2   2   0   0   1   6   9   1   0   0   0  25   0   7   4   7   0\n",
      "    0   1   0   0   5   2   5  14   0  10   0   2   1   0]\n",
      " [  6  23   6   0   0   4   1   0   0   1   1   4   0   2   0   0   1   2\n",
      "    0   7   7   4   5   0   3  14   0   0   7   0   5   0   6   0  41   1\n",
      "    3   0   0   0   4   0  11  14   0   0   4   0   9   0   1  12   9   4\n",
      "    0   0   2  10   0   0   0   2  14   1   0  17   1   1   0   1   1   0\n",
      "    3   1   0   4   0   0   8   6   0   4   0   0   0   0   0   0   2   0\n",
      "   32   1   3  25   0   0   0   3   1   0   0   7   0   1   9   0   1   2\n",
      "    3   1   1   2   0   4   0   1   3   3  35   1   0   0   0   0   1   4\n",
      "   17   0   0   0   9   0   2   5   8   4   0   1   0   0   0  28   0   0\n",
      "    0  13   0   3   3   0   6   1   2   3   0   0   0   2   9   5  24   0\n",
      "    5   1   2   0   2   0  69   0   2   0  17   4  24   0   0   0   0  17\n",
      "    0   0   3   0  19   5   2   0   5   0   0   5   0   1   0   0   1   1\n",
      "    1   0   0   0   0   0   0   2   1   1   0   6   9   0   2   1   1  58\n",
      "    1   4   3  12   2   0   8   5  20   6   0   0   0   0   0   2   5  11\n",
      "    0   0   0   9   2   0   4   4  89   0  11   0   2   8   0   0   2   2\n",
      "    1  33   1   7   1   8   2   0   9   2   3   1   0   8   0   0  29   8\n",
      "   15   3   0   0   2   0   0   0   2   0   9   9  24   0   1  14   0   2\n",
      "  121   0   0   7  12   3   0   4   9   4  15   4   5   0   6   7   0   0\n",
      "    1   3   1   0   4   1   2   0   0   0   0   1   8  19]]\n",
      "tensor(111.5769)\n",
      "------------\n",
      "Sinkhorn quantization iter: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states.std: 0.9999868273735046\n",
      "weight_proj.std: 1.0001189708709717\n",
      "hidden_states.std after weight_proj: 16.074504852294922\n",
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L [[10  9  3  1  2  2  1  4 11 10  0  3  1  2  4  2  3  2  3  2  3  4  1 23\n",
      "   2  2 13  8  7  7  3  0 14  6  6  3  2  2  1  4  7 13  3  2  2  3  0  8\n",
      "   4  5  2  2  7  2  5  4  7  3 10  4  6  3  3  2  1  4  3  1 25  1  2  2\n",
      "   3  2  3  5  5  1  3  2  2  5  3  4  8  4  5  4  5  1  2  3  4  2  1  2\n",
      "   8  4  4  3  2  0  6  2  2  3  7  1  1  2  1  1  1  6  3  2  9 17  2  3\n",
      "  11  4  2 10  4  1  5  2  5  1 16  4  1 10  2 10 12  3  3  3  1  3  2  5\n",
      "   1  5  8 10 10  6  1  2  5  2  1  3 11 27 16  3  5  4  3  2  1 17  6  3\n",
      "   3  4  2  3  7  2 11  2  2  1  4  5  1 13  2  3  2  2  3  1  3  3 10  6\n",
      "   4  8 13 15  2  4  5  4  4  1  4  6  0  3  3  2  2 54  1  2  3  3 15  3\n",
      "   7  2  1  6  6  3  2  4  3  4  1  5  6  2  2  3  3 15 10  2  2 11  1  1\n",
      "   9  4  3  1  2  7  4  2  4  2  4  7  1  6  3 12  6  2  2  6 11  3 11  4\n",
      "   1  8  5  5  3  3  5  2  8 11  5  1  3  4  2  1  1  2  2  1  1  1  2  4\n",
      "   7  9  3  5  1  3  3  3  2  2 10  2  3  3  2  2  2  2 38  3  4  2  4  6\n",
      "   3  2  1  5 11 13 11  4]\n",
      " [ 1  1  3  3  5  2  6  4  6  1  1  4  5  5  5  7  4  2  3  5  5 12  3  6\n",
      "   5  4  3  1  9  2  6  2  1  1  2  1  3  2  3 10  1  1  3  5  2  6  3  2\n",
      "  11  6  1  7 10  1  6  8  1  0  5 14 36  2  9  5  7  2  2  1  4  5  6  2\n",
      "  14  6  5  7  1  2  1  4  5  5  6  7  5  4  1  2  3  2  1  9  9  2  3  5\n",
      "   5  1  2  4 14  2 25  1  1  6  2  5  7  8  4  5  4  6  3  4  2  3  1  2\n",
      "   4  3  3  2  1 10  3  1  2  3  6  1 35  2  2  4 10  5 11  3  2  2  5  1\n",
      "   2  2  3 24  3  8  4  2  4  3  4  7 12  9  4 11  7  7  3  4  3  0  4  4\n",
      "   3  2  2  4  3  4 13  1  4  2  2 10  5  8  6  2  1  4  2  2  3  2  7 25\n",
      "   1  9  3  6  2  1  6  4  4  3  6  2  1  3  1  3  1  2  3  3 13  0  8  0\n",
      "   9  4  2  3  2 47  1 12  3  2  5  2  1  8  2  0  5  4  3  5  1  5  4  2\n",
      "   6  3  5  1  2  6  6  3  1  4  5  2  4  6  8  2  3  6  2 10  5  3  6  3\n",
      "   1  2  1 12  1  6  6  2  1  4  4  3  5  6  5  3  7  2  1  3  1  2  3  2\n",
      "   3  3  3  4  4  3 11 15  4  2  5  3 34  5  7  4  2  9  3  2  3  1  2 11\n",
      "   3  3  5  2  2  8  2  3]]\n",
      "tensor(182.2257)\n",
      "------------\n",
      "Sinkhorn quantization iter: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states.std: 0.9999868273735046\n",
      "weight_proj.std: 1.0001189708709717\n",
      "hidden_states.std after weight_proj: 16.074504852294922\n",
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L [[ 6  7  4  6  4  6  3  4  8  7  5  4  3  3  5  3  5  3  4  3  3  5  7 12\n",
      "   3  2  7  6  6  5  4  5  7  7  5  4  3  3  4  6  5 10  4  4  5  3  3  5\n",
      "   4  5  6  4  6  4  6  5  7  7  7  4  4  3  5  2  1  5  3  5  8  2  3  4\n",
      "   6  4  2  5  5  4  3  4  2  5  6  4  5  6  7  5  5  4  2  3  4  4  4  5\n",
      "   5  4  5  3  4  1  4  3  4  3  7  2  4  7  3  5  6  4  4  7  7 11  2  4\n",
      "   7  3  4  4  7  3  6  5  5  3 10  4  3  4  3  5  8  3  6  3  3  6  3  6\n",
      "   1  4  7  6  8  5  4  2  4  4  2  5  3  8  7  5  5  6  4  3  3  8  6  4\n",
      "   5  6  5  5  6  3  5  3  3  2  7  6  4  9  3  5  3  3  4  1  6  5  8  5\n",
      "   4  7  7  7  2  6  5  5  6  2  4  5  3  4  4  4  4 14  3  3  4  4  7  6\n",
      "   5  4  3  5  6  4  7  4  4  6  3  4  6  3  3  3  7  8  6  2  3  7  3  3\n",
      "   8  3  5  3  4  5  4  5  5  4  5  6  1  5  3  4  6  3  4  5  9  6  9  4\n",
      "   4  6  6  4  4  5  5  2  5  9  4  3  6  4  5  2  2  3  4  4  2  2  4  5\n",
      "   4  6  5  6  3  4  4  5  4  6  7  4  4  4  2  3  4  3 12  6  5  4  4  3\n",
      "   4  4  5  5  7  8  6  4]\n",
      " [ 5  2  4  4  5  4  6  5  4  3  3  4  5  4  4  6  6  4  3  6  5  6  4  4\n",
      "   5  4  3  3  6  3  4  3  5  2  3  3  5  4  6  8  3  3  5  5  5  5  5  4\n",
      "   7  6  4  5  8  4  6  4  2  3  6 12  6  5  5  5  6  3  3  2  4  7  5  6\n",
      "   8  4  7  6  2  5  2  5  5  5  5  7  6  3  4  2  4  3  6  4  8  4  4  3\n",
      "   6  3  4  6  9  6 11  2  3  4  3  5  4  6  4  4  4  6  4  6  5  4  3  5\n",
      "   5  5  4  2  6  8  3  3  5  3  5  5 10  4  3  4  6  5  6  4  4  3  5  2\n",
      "   3  3  5 10  4  7  6  4  5  3  5  5 10  6  4  8  6  6  3  6  4  4  3  4\n",
      "   4  4  5  4  3  5  6  2  5  3  4  6  5  5  5  6  2  5  4  3  4  4  5  9\n",
      "   4  6  5  6  2  5  8  4  5  3  7  4  4  4  2  3  3  4  2  4  8  4  6  4\n",
      "   5  8  5  5  4 18  3  7  5  4  6  3  4  5  3  4  4  4  4  5  3  7  4  2\n",
      "   5  5  5  3  4  6  6  3  1  4  5  4  4  5  5  4  5  4  5  7  7  4  5  7\n",
      "   2  4  3  5  3 10  8  2  3  5  5  6  5  6  6  4  7  5  2  4  1  3  5  2\n",
      "   4  5  5  4  4  3  5  7  6  4  3  4 10  6  6  3  3  5  5  3  3  2  6  9\n",
      "   3  4  5  4  4  5  4  4]]\n",
      "tensor(182.2257)\n",
      "------------\n",
      "Sinkhorn quantization iter: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states.std: 0.9999868273735046\n",
      "weight_proj.std: 1.0001189708709717\n",
      "hidden_states.std after weight_proj: 16.074504852294922\n",
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L [[ 5  5  5  6  4  5  5  3  7  7  5  4  4  4  6  4  6  5  4  3  4  5  7 10\n",
      "   6  5  5  5  5  4  5  5  6  6  5  5  3  4  3  7  5  8  5  3  5  5  3  6\n",
      "   5  4  6  4  4  4  6  6  5  5  7  5  6  4  4  3  3  5  3  6  7  3  4  4\n",
      "   6  4  4  5  5  4  4  4  2  5  6  5  5  5  7  6  5  3  2  3  4  5  2  5\n",
      "   5  4  5  3  4  3  5  4  4  3  5  3  5  6  4  5  5  3  4  6  6  5  3  5\n",
      "   4  3  4  5  6  4  5  4  4  4  9  5  4  4  4  4  7  4  6  4  3  6  3  5\n",
      "   2  4  6  6  6  6  3  4  3  5  5  5  2  5  6  5  5  7  5  3  4  6  5  6\n",
      "   5  6  5  6  6  3  4  3  3  3  7  6  6  6  3  5  6  5  4  4  3  4  5  5\n",
      "   6  6  5  6  2  6  5  5  5  4  4  5  4  4  4  4  6  8  5  6  3  4  5  6\n",
      "   5  4  3  5  4  4  7  5  4  5  3  4  7  3  3  4  5  7  6  2  3  5  4  3\n",
      "   6  3  6  3  5  4  5  5  6  4  6  6  4  6  3  4  5  4  5  3  5  6  7  5\n",
      "   5  6  6  5  4  6  5  2  6  7  4  3  6  4  3  2  1  4  4  6  4  3  4  5\n",
      "   3  6  6  6  5  4  4  5  4  5  6  5  6  4  3  4  4  4  5  5  5  4  4  4\n",
      "   4  4  5  5  7  6  5  4]\n",
      " [ 5  3  5  5  5  4  5  5  3  4  5  5  4  5  5  5  6  4  4  6  5  4  5  5\n",
      "   5  4  3  5  6  3  5  5  5  3  5  3  4  3  5  7  4  2  6  5  5  4  5  3\n",
      "   6  5  5  4  8  4  6  3  3  5  6  5  5  5  5  5  5  3  3  4  4  6  5  6\n",
      "   5  4  6  6  3  5  3  5  5  6  5  6  6  4  6  4  4  3  7  4  5  4  4  3\n",
      "   6  2  5  6  8  4  5  3  6  4  4  5  4  5  4  5  5  7  4  5  5  5  3  4\n",
      "   5  6  5  2  5  5  4  3  5  3  6  5  6  5  5  4  5  5  6  4  5  4  5  3\n",
      "   4  4  5  6  4  7  6  4  5  5  6  4  7  5  4  8  6  4  4  5  4  5  3  4\n",
      "   4  3  5  5  5  5  4  4  5  4  3  6  5  5  5  4  3  5  6  3  4  4  4  7\n",
      "   4  5  5  6  2  4  8  3  5  2  7  4  4  4  4  4  4  4  2  4  6  4  4  4\n",
      "   4  9  7  5  5  9  3  7  4  5  6  3  5  4  2  4  4  6  4  6  3  7  5  3\n",
      "   4  5  5  4  7  6  6  4  2  5  4  4  5  4  5  5  6  4  6  6  5  4  5  6\n",
      "   5  5  4  5  4  8  6  4  3  5  5  6  4  5  6  5  4  5  4  6  4  3  5  3\n",
      "   5  5  4  4  5  3  4  5  6  5  3  5  6  6  5  3  4  5  5  3  5  3  5  7\n",
      "   5  5  5  4  5  4  4  4]]\n",
      "tensor(182.2257)\n"
     ]
    }
   ],
   "source": [
    "model_output = {}\n",
    "# for model_name in MODEL_NAMES:\n",
    "config = Wav2Vec2Config.from_pretrained(\n",
    "  '/scicore/home/dokman0000/liu0003/projects/seisLM/seisLM/configs/pretrain/model_config_4xdownsample_sinkhorn.json'\n",
    ")\n",
    "\n",
    "\n",
    "# config.sinkhorn_quantization_iters = 1\n",
    "\n",
    "for sinkhorn_quantization_iter in [0, 1, 3, 5]:\n",
    "  print('------------')\n",
    "  print(f\"Sinkhorn quantization iter: {sinkhorn_quantization_iter}\")\n",
    "  config.sinkhorn_quantization_iters = sinkhorn_quantization_iter\n",
    "  model = MultiDimWav2Vec2ForPreTraining(config)\n",
    "\n",
    "  # compute masked indices\n",
    "  batch_size, num_channels, raw_sequence_length = input_values.shape\n",
    "  sequence_length = model._get_feat_extract_output_lengths(\n",
    "    raw_sequence_length).item()\n",
    "\n",
    "  seed_everything(0)\n",
    "  mask_time_indices = _compute_mask_indices(\n",
    "      shape=(batch_size, sequence_length), mask_prob=0.2, mask_length=2\n",
    "  )\n",
    "  sampled_negative_indices = _sample_negative_indices(\n",
    "      features_shape=(batch_size, sequence_length),\n",
    "      num_negatives=model.config.num_negatives,\n",
    "      mask_time_indices=mask_time_indices,\n",
    "  )\n",
    "  mask_time_indices = torch.tensor(\n",
    "    data=mask_time_indices, device=input_values.device, dtype=torch.long)\n",
    "  sampled_negative_indices = torch.tensor(\n",
    "    data=sampled_negative_indices, device=input_values.device,\n",
    "    dtype=torch.long\n",
    "  )\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(input_values, mask_time_indices=mask_time_indices,\n",
    "                    sampled_negative_indices=sampled_negative_indices)\n",
    "\n",
    "\n",
    "  print(outputs.codevector_perplexity)\n",
    "  # model_output[f'{model_name}_{model_type}'] = outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Sinkhorn quantization iter: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states.std: 0.9999868273735046\n",
      "weight_proj.std: 1.0001189708709717\n",
      "hidden_states.std after weight_proj: 16.074504852294922\n",
      "hidden_states.std after scaling: 1.0046565532684326\n",
      "denom: 16.0\n",
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L [[ 6  5  4  3  6  3  1  5  9 10  1  5  4  2  6  1  4  1  1  7  2  3  6  9\n",
      "   4  1  4  6  5  8  1  8  8  6  9  1  4  5  6  3 10  7  4  3  7  4  6  7\n",
      "   2  6  2  1  6  6  6  2  5  7  3  8  8  2  4  4  4  0  3  4 13  3  1  3\n",
      "   3  8  6  7  8  1  4  5  5  0  5  5  7  8  3  4  7  4  3  7  3  3  3  4\n",
      "   7  3  1  3  2  4  5  2  2  5  6  1  4  6  3  7  4  4  2  0  9 10  3  1\n",
      "   3  1  3  6  3  3  3 11  2  3  6  6  1  7  1 17  9  4  2  3  0  6  0  5\n",
      "   3  5  6  4  9  6  8  5  7  2  3  8 10  9  4  7  7  4  3  7  1  6  5  1\n",
      "   3  3  1  2  5  4  6  2  4  8  3  6  3  5  2  4  4  3  2  1  4  3  6  5\n",
      "   4  7  7  8  4  3  4  3  7  5  4  8  2  3  5  3  4 14  5  1  2  5  7  1\n",
      "   6  5  3  3  7  5  4  5 13  5  3 10  6  5  3  4  8  7  9  6  2  3  3  4\n",
      "   4  8  3  4  2  7  7  3  2  7  6  7  4  7  7  5  6  2  6  9  6  3 10  5\n",
      "   4  3  5  1  1  5  7  7  9 10  4  2  1  3  9  0  7  5  5  2  1  5  1  9\n",
      "   7  8  0  1  8  4  3  5  3  4  3  5  3  1  6  2  6  3 10  6  4  5  2  7\n",
      "   1  3  5  7  9  3 14  5]\n",
      " [ 2  3  0  2  3  4  4  5  6  2  5  3  6  5  3  4  7  5  2  7  7  9  4  8\n",
      "   4  7  6  1  8  2  6  2  6  3  1  5  7  3  2  7  0  1  5  5  6  8  7  2\n",
      "   9  9  7  7  8  3  7  8  2  5  5  9 10  3  7  9  3  5  5  2  4  9  7  2\n",
      "   6  4  7  7  1  3  6  4  8  3  9  4  5  2  2  3  6  2  1  9  8  2  5  3\n",
      "   4  4  3  4 11  3  4  3  2  4  2  7  7  5  5  6  6  5  6  7  2  4  2  7\n",
      "   7  1  5  4  2  7  4  2  5  2 11  1 11  4  3  4  6  4 10  8  5  2  0  3\n",
      "   2  9  7 12  6  9  1  2  3  6  3  9  7  8  1  6  4  7  7  7  2  4  4  6\n",
      "   4  8  7  6  4  4  4  2  5  7  2 15  4  7  6  3  0  5  4  4  5  2  8  6\n",
      "   3  5  6  5  5  6  5  6  5  5  5  7  5  3  5  2  1  6  5  1  2  4  5  1\n",
      "   7  6  6  2  4  9  4  6  1  4  6  2  3 11  1  3  1  7  6  2  3  9  4  4\n",
      "   3  3  8  3  3  6  5  2  1  1  1  3  2  7  7  0  2  3  2 10  4  5  2  4\n",
      "   1  5  0  7  3  5  1  8  2  3  4  3  9  2 13  1  7  1  5  3  2  5  3  4\n",
      "   2  3  0  4  4  4  5  7  3  4  0  1 14  5  7  6  5  5  4  2  5  4  6 11\n",
      "   6  8  8  5  6  6  5  3]]\n",
      "tensor(591.2267)\n",
      "------------\n",
      "Sinkhorn quantization iter: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states.std: 0.9999868273735046\n",
      "weight_proj.std: 1.0001189708709717\n",
      "hidden_states.std after weight_proj: 16.074504852294922\n",
      "hidden_states.std after scaling: 1.0046565532684326\n",
      "denom: 16.0\n",
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L [[ 3  6  4  2  7  4  2  3  7  8  5  5  7  3  7  3  4  1  1  6  2  6  7  5\n",
      "   5  4  4  6  4  6  3  6  6  5  9  2  4  8  6  3  5  3  5  3  7  8  3  6\n",
      "   2  6  5  3  6  6  2  4  4  7  3  6 10  4  4  7  4  0  3  9  3  7  2  3\n",
      "   2  8  6  3  5  5  4  5  9  2  5  5  4  7  6  4  7  8  3  8  2  3  6  3\n",
      "   6  4  3  5  4  4  5  4  3  4  4  4  7  5  5  5  7  4  4  3  6  7  4  2\n",
      "   3  1  3  6  2  6  4  9  3  4  5  5  4  5  1  7  8  5  3  3  4  6  4  5\n",
      "   3  8  6  3  4  4  8  6  4  4  6  8  9  7  2  5  5  4  6  7  2  5  2  2\n",
      "   6  2  4  2  3  5  3  2  3  7  6  5  4  4  3  3  5  4  3  5  5  5  5  6\n",
      "   7  5  5  5  4  5  3  4  7  4  4  6  6  2  5  4  5  5  4  2  3  5  5  4\n",
      "   4  6  4  4  7  4  5  5  8  2  5  6  3  6  4  9  9  5  7  7  3  3  4  5\n",
      "   5  8  6  5  2  6  6  6  1  8  4  6  3  4  4  4  1  6  7  7  5  3  5  5\n",
      "   6  3  5  1  2  9  6  7  5  4  5  2  1  5  7  3  5  9  5  2  3  4  1 11\n",
      "   4  4  2  2  7  6  3  4  2  4  3  5  5  3  5  2  9  3  4  5  5  8  5  6\n",
      "   2  4  5  9  6  3  3  5]\n",
      " [ 4  6  1  2  3  5  2  1  6  4  7  4  6  5  4  3  6  5  6  6  6  6  4  4\n",
      "   4  6  6  1  9  7  5  5  8  4  3  6  8  4  2  4  3  3  5  7  6  5  6  2\n",
      "   7  5  7  7  7  4  6  5  2  6  2  8  4  6  6  6  1  8  5  5  5  8  8  3\n",
      "   7  3  7  3  3  5  6  2  5  4  5  4  7  3  2  4 10  1  2  7  8  6  4  4\n",
      "   6  5  4  5  7  3  3  3  2  4  4  6  7  5  4  6  5  5  9  8  6  4  3  4\n",
      "   7  2  5  4  2  4  4  3  5  2  8  2  4  4  4  3  4  5  7  7  7  3  2  6\n",
      "   3  7  4  6  7  7  3  1  4  6  5  6  5  5  3  4  4  5  4  7  3  4  2  5\n",
      "   6  5  7  6  4  5  0  6  5  6  3  9  2  2  5  4  3  4  5  5  5  4  5  6\n",
      "   4  4  5  4  4  6  5  7  5  5  5  8  5  4  6  2  2  6  6  3  4  6  4  3\n",
      "   4  8  6  4  3  6  4  4  1  4  7  3  5  6  2  5  2  6  5  2  5 10  6  5\n",
      "   3  3 10  6  4  5  3  5  4  1  5  3  4  8  7  5  3  5  4  8  5  4  2  3\n",
      "   1  5  5  4  4  5  2  6  3  2  5  3  8  2  4  6  4  4  6  5  3  4  4  4\n",
      "   3  4  1  5  5  5  2  8  4  5  0  1  4  5  5  6  2  4  4  3  6  6  6  9\n",
      "   6  9  8  5  8  5  5  3]]\n",
      "tensor(591.2267)\n",
      "------------\n",
      "Sinkhorn quantization iter: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states.std: 0.9999868273735046\n",
      "weight_proj.std: 1.0001189708709717\n",
      "hidden_states.std after weight_proj: 16.074504852294922\n",
      "hidden_states.std after scaling: 1.0046565532684326\n",
      "denom: 16.0\n",
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L [[ 3  6  4  2  7  4  2  3  7  8  5  5  7  3  7  3  4  1  1  6  2  6  7  5\n",
      "   5  4  4  6  4  6  3  6  6  5  9  3  4  8  6  3  5  3  5  3  7  8  3  6\n",
      "   2  6  5  3  6  5  2  4  4  7  3  5 10  4  4  7  4  0  3  9  3  7  2  3\n",
      "   2  8  6  3  5  5  4  4  9  2  5  6  4  7  6  4  7  8  3  8  2  3  6  3\n",
      "   6  4  3  5  4  4  5  4  3  4  4  4  7  5  5  5  7  4  4  3  6  7  4  2\n",
      "   3  1  3  6  2  6  4  9  3  4  5  5  4  5  1  7  8  5  3  3  4  6  4  5\n",
      "   3  8  6  3  4  4  8  6  4  4  6  8  9  7  2  5  5  4  6  7  2  5  2  2\n",
      "   6  2  4  3  3  5  3  2  3  7  6  5  4  4  3  3  5  4  3  5  5  5  5  6\n",
      "   7  5  5  5  4  5  3  4  7  4  4  6  6  2  5  4  5  5  4  2  3  5  5  4\n",
      "   4  6  4  4  7  4  5  5  8  2  5  6  3  6  4  9  9  5  7  7  3  3  4  5\n",
      "   5  8  6  5  2  6  6  6  1  8  4  6  3  4  4  4  1  6  7  7  5  3  5  5\n",
      "   6  3  5  1  2  9  6  7  5  4  5  2  1  5  7  3  5  9  5  2  3  4  1 11\n",
      "   4  4  2  2  7  6  3  4  2  4  3  5  5  3  5  2  9  3  4  5  5  8  5  6\n",
      "   2  4  5  9  6  3  3  5]\n",
      " [ 4  6  1  2  3  5  2  1  6  4  7  4  6  5  4  3  6  5  6  6  6  6  4  4\n",
      "   4  6  6  1  9  7  5  5  8  4  3  6  8  4  2  4  3  3  5  7  6  5  6  2\n",
      "   7  5  7  7  7  4  6  5  2  6  2  8  4  6  6  6  1  8  5  5  6  8  8  3\n",
      "   7  3  7  3  3  5  6  2  5  4  5  4  7  3  2  4 10  1  2  7  8  6  4  4\n",
      "   6  5  4  5  7  3  3  3  2  4  4  6  7  5  4  6  5  5  9  8  6  4  3  4\n",
      "   7  2  5  4  2  4  4  3  5  2  8  2  4  4  4  3  4  5  7  7  7  3  2  6\n",
      "   3  7  4  6  7  7  3  1  4  6  5  6  5  5  3  4  4  5  4  7  3  4  2  5\n",
      "   6  5  7  6  4  5  0  6  5  6  3  9  2  2  5  4  3  4  5  5  5  4  5  6\n",
      "   4  4  5  4  4  6  5  7  5  5  5  8  5  4  6  2  2  6  5  4  4  6  4  3\n",
      "   4  8  6  4  3  6  4  4  1  4  7  3  5  5  2  5  2  6  5  2  5 10  6  5\n",
      "   3  3 10  6  4  5  3  5  4  1  5  3  4  8  7  5  3  5  4  8  5  4  2  3\n",
      "   1  5  5  4  4  5  2  6  3  2  5  3  8  2  4  6  4  4  6  5  3  4  4  4\n",
      "   3  4  1  5  5  5  2  8  4  5  0  1  4  5  5  6  2  4  4  3  6  6  6  9\n",
      "   6  9  8  5  8  5  5  3]]\n",
      "tensor(591.2267)\n",
      "------------\n",
      "Sinkhorn quantization iter: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states.std: 0.9999868273735046\n",
      "weight_proj.std: 1.0001189708709717\n",
      "hidden_states.std after weight_proj: 16.074504852294922\n",
      "hidden_states.std after scaling: 1.0046565532684326\n",
      "denom: 16.0\n",
      "codevector_probs.shape [B * L, G, V]: torch.Size([1499, 2, 320])\n",
      "codevector_probs sum over B*L [[ 3  6  4  2  7  4  2  3  7  8  5  5  7  3  7  3  4  1  1  6  2  6  7  5\n",
      "   5  4  4  6  4  6  3  6  6  5  9  3  4  8  6  3  5  3  5  3  7  8  3  6\n",
      "   2  6  5  3  6  5  2  4  4  7  3  5 10  4  4  7  4  0  3  9  3  7  2  3\n",
      "   2  8  6  3  5  5  4  4  9  2  5  6  4  7  6  4  7  8  3  8  2  3  6  3\n",
      "   6  4  3  5  4  4  5  4  3  4  4  4  7  5  5  5  7  4  4  3  6  7  4  2\n",
      "   3  1  3  6  2  6  4  9  3  4  5  5  4  5  1  7  8  5  3  3  4  6  4  5\n",
      "   3  8  6  3  4  4  8  6  4  4  6  8  9  7  2  5  5  4  6  7  2  5  2  2\n",
      "   6  2  4  3  3  5  3  2  3  7  6  5  4  4  3  3  5  4  3  5  5  5  5  6\n",
      "   7  5  5  5  4  5  3  4  7  4  4  6  6  2  5  4  5  5  4  2  3  5  5  4\n",
      "   4  6  4  4  7  4  5  5  8  2  5  6  3  6  4  9  9  5  7  7  3  3  4  5\n",
      "   5  8  6  5  2  6  6  6  1  8  4  6  3  4  4  4  1  6  7  7  5  3  5  5\n",
      "   6  3  5  1  2  9  6  7  5  4  5  2  1  5  7  3  5  9  5  2  3  4  1 11\n",
      "   4  4  2  2  7  6  3  4  2  4  3  5  5  3  5  2  9  3  4  5  5  8  5  6\n",
      "   2  4  5  9  6  3  3  5]\n",
      " [ 4  6  1  2  3  5  2  1  6  4  7  4  6  5  4  3  6  5  6  6  6  6  4  4\n",
      "   4  6  6  1  9  7  5  5  8  4  3  6  8  4  2  4  3  3  5  7  6  5  6  2\n",
      "   7  5  7  7  7  4  6  5  2  6  2  8  4  6  6  6  1  8  5  5  6  8  8  3\n",
      "   7  3  7  3  3  5  6  2  5  4  5  4  7  3  2  4 10  1  2  7  8  6  4  4\n",
      "   6  5  4  5  7  3  3  3  2  4  4  6  7  5  4  6  5  5  9  8  6  4  3  4\n",
      "   7  2  5  4  2  4  4  3  5  2  8  2  4  4  4  3  4  5  7  7  7  3  2  6\n",
      "   3  7  4  6  7  7  3  1  4  6  5  6  5  5  3  4  4  5  4  7  3  4  2  5\n",
      "   6  5  7  6  4  5  0  6  5  6  3  9  2  2  5  4  3  4  5  5  5  4  5  6\n",
      "   4  4  5  4  4  6  5  7  5  5  5  8  5  4  6  2  2  6  5  4  4  6  4  3\n",
      "   4  8  6  4  3  6  4  4  1  4  7  3  5  5  2  5  2  6  5  2  5 10  6  5\n",
      "   3  3 10  6  4  5  3  5  4  1  5  3  4  8  7  5  3  5  4  8  5  4  2  3\n",
      "   1  5  5  4  4  5  2  6  3  2  5  3  8  2  4  6  4  4  6  5  3  4  4  4\n",
      "   3  4  1  5  5  5  2  8  4  5  0  1  4  5  5  6  2  4  4  3  6  6  6  9\n",
      "   6  9  8  5  8  5  5  3]]\n",
      "tensor(591.2267)\n"
     ]
    }
   ],
   "source": [
    "model_output = {}\n",
    "# for model_name in MODEL_NAMES:\n",
    "config = Wav2Vec2Config.from_pretrained(\n",
    "  '/scicore/home/dokman0000/liu0003/projects/seisLM/seisLM/configs/pretrain/model_config_4xdownsample_sinkhorn.json'\n",
    ")\n",
    "config.scale_logits_in_quantization = True\n",
    "\n",
    "for sinkhorn_quantization_iter in [0, 1, 3, 5]:\n",
    "  print('------------')\n",
    "  print(f\"Sinkhorn quantization iter: {sinkhorn_quantization_iter}\")\n",
    "  config.sinkhorn_quantization_iters = sinkhorn_quantization_iter\n",
    "  model = MultiDimWav2Vec2ForPreTraining(config)\n",
    "\n",
    "  # compute masked indices\n",
    "  batch_size, num_channels, raw_sequence_length = input_values.shape\n",
    "  sequence_length = model._get_feat_extract_output_lengths(\n",
    "    raw_sequence_length).item()\n",
    "\n",
    "  seed_everything(0)\n",
    "  mask_time_indices = _compute_mask_indices(\n",
    "      shape=(batch_size, sequence_length), mask_prob=0.2, mask_length=2\n",
    "  )\n",
    "  sampled_negative_indices = _sample_negative_indices(\n",
    "      features_shape=(batch_size, sequence_length),\n",
    "      num_negatives=model.config.num_negatives,\n",
    "      mask_time_indices=mask_time_indices,\n",
    "  )\n",
    "  mask_time_indices = torch.tensor(\n",
    "    data=mask_time_indices, device=input_values.device, dtype=torch.long)\n",
    "  sampled_negative_indices = torch.tensor(\n",
    "    data=sampled_negative_indices, device=input_values.device,\n",
    "    dtype=torch.long\n",
    "  )\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(input_values, mask_time_indices=mask_time_indices,\n",
    "                    sampled_negative_indices=sampled_negative_indices)\n",
    "\n",
    "\n",
    "  print(outputs.codevector_perplexity)\n",
    "  # model_output[f'{model_name}_{model_type}'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seisbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
