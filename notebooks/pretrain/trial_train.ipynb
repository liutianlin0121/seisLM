{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import ml_collections\n",
    "import lightning as L\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from seisLM.model.foundation.pretrained_models import LitMultiDimWav2Vec2\n",
    "from seisLM.data_pipeline import collator\n",
    "from seisLM.data_pipeline import seisbench_dataloaders as dataloaders\n",
    "from seisLM.utils import project_path\n",
    "from seisLM.utils.wandb_utils import shutdown_cleanup_thread\n",
    "from seisLM.utils.config_utils import ConfigTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in test mode\n",
      "ddp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_config.amp_norm',\n",
       " 'data_config.amp_norm_type',\n",
       " 'data_config.cache_dataset',\n",
       " 'data_config.data_name',\n",
       " 'data_config.demean',\n",
       " 'data_config.local_batch_size',\n",
       " 'data_config.prefetch_factor',\n",
       " 'data_config.training_fraction',\n",
       " 'model_config.activation_dropout',\n",
       " 'model_config.apply_spec_augment',\n",
       " 'model_config.attention_dropout',\n",
       " 'model_config.codevector_dim',\n",
       " 'model_config.contrastive_logits_temperature',\n",
       " 'model_config.conv_bias',\n",
       " 'model_config.conv_dim',\n",
       " 'model_config.conv_kernel',\n",
       " 'model_config.conv_stride',\n",
       " 'model_config.diversity_loss_weight',\n",
       " 'model_config.do_stable_layer_norm',\n",
       " 'model_config.feat_extract_norm',\n",
       " 'model_config.feat_proj_dropout',\n",
       " 'model_config.feat_quantizer_dropout',\n",
       " 'model_config.hidden_dropout',\n",
       " 'model_config.hidden_size',\n",
       " 'model_config.initializer_range',\n",
       " 'model_config.input_dim',\n",
       " 'model_config.intermediate_size',\n",
       " 'model_config.layer_norm_eps',\n",
       " 'model_config.layerdrop',\n",
       " 'model_config.mask_feature_length',\n",
       " 'model_config.mask_feature_min_masks',\n",
       " 'model_config.mask_feature_prob',\n",
       " 'model_config.mask_time_length',\n",
       " 'model_config.mask_time_min_masks',\n",
       " 'model_config.mask_time_prob',\n",
       " 'model_config.num_attention_heads',\n",
       " 'model_config.num_codevector_groups',\n",
       " 'model_config.num_codevectors_per_group',\n",
       " 'model_config.num_conv_pos_embedding_groups',\n",
       " 'model_config.num_conv_pos_embeddings',\n",
       " 'model_config.num_feat_extract_layers',\n",
       " 'model_config.num_hidden_layers',\n",
       " 'model_config.num_negatives',\n",
       " 'model_config.output_attentions',\n",
       " 'model_config.output_hidden_size',\n",
       " 'model_config.output_hidden_states',\n",
       " 'model_config.pad_token_id',\n",
       " 'model_config.proj_codevector_dim',\n",
       " 'model_config.scale_logits_in_quantization',\n",
       " 'model_config.use_rms_norm',\n",
       " 'seed',\n",
       " 'training_config.accelerator',\n",
       " 'training_config.adam_beta1',\n",
       " 'training_config.adam_beta2',\n",
       " 'training_config.adam_epsilon',\n",
       " 'training_config.devices',\n",
       " 'training_config.learning_rate',\n",
       " 'training_config.log_every_n_steps',\n",
       " 'training_config.mask_time_length',\n",
       " 'training_config.mask_time_prob',\n",
       " 'training_config.max_epochs',\n",
       " 'training_config.max_gumbel_temperature',\n",
       " 'training_config.min_gumbel_temperature',\n",
       " 'training_config.precision',\n",
       " 'training_config.warmup_frac_step',\n",
       " 'training_config.weight_decay'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = '/scicore/home/dokman0000/liu0003/projects/seisLM/seisLM/configs/pretrain/pretrain_config_layernorm_peak.json'\n",
    "\n",
    "with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "  config = json.load(f)\n",
    "config = ml_collections.ConfigDict(config)\n",
    "\n",
    "DEFAULT_NUM_WORKERS = 8\n",
    "\n",
    "print(\"Running in test mode\")\n",
    "config.training_config.max_epochs = 1\n",
    "config.data_config.data_name = ['ETHZ']\n",
    "config.data_config.local_batch_size = 8\n",
    "\n",
    "\n",
    "tracked_config = ConfigTracker(config)\n",
    "\n",
    "print(config.training_config.accelerator)\n",
    "\n",
    "aa = tracked_config.get_unused_keys()\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Unused keys: {'b.c', 'b.d', 'e'}\n",
      "a: 1\n",
      "b:\n",
      "  c: 2\n",
      "  d: 3\n",
      "e: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ml_collections\n",
    "\n",
    "config_dict = ml_collections.ConfigDict()\n",
    "config_dict.a = 1\n",
    "config_dict.b = ml_collections.ConfigDict()\n",
    "config_dict.b.c = 2\n",
    "config_dict.b.d = 3\n",
    "config_dict.e = 4\n",
    "\n",
    "# Wrap the config in the tracker\n",
    "tracked_config = ConfigTracker(config_dict)\n",
    "\n",
    "# Access some configuration fields\n",
    "print(tracked_config.a)        # Access 'a'\n",
    "print(tracked_config.b.c)      # Access 'b.c'\n",
    "\n",
    "# Get unused fields\n",
    "unused_keys = tracked_config.get_unused_keys()\n",
    "print(\"Unused keys:\", unused_keys)\n",
    "print(config_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seisbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
