{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liu0003/miniconda3/envs/seisbench/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "import seisbench.data as sbd\n",
    "import seisbench.generate as sbg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seisbench.util import worker_seeding\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "from seisLM.utils import project_path\n",
    "\n",
    "from seisLM.model.foundation.pretrained_models import LitMultiDimWav2Vec2, MultiDimWav2Vec2ForPreTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader\n",
    "\n",
    "1. only extract 1000 samples for each class (earthquake vs noise)\n",
    "2. return meta data for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaDataKeepingSteeredGenerator(sbg.SteeredGenerator):\n",
    "  def _clean_state_dict(self, state_dict):\n",
    "    # Remove control information\n",
    "    trace_type = state_dict[\"_control_\"][\"trace_type\"]\n",
    "\n",
    "    X, meta = state_dict[\"X\"]\n",
    "    path_ep_distance_km = meta.get(\"path_ep_distance_km\", np.inf)\n",
    "    path_hyp_distance_km = meta.get(\"path_hyp_distance_km\", np.inf)\n",
    "\n",
    "    state_dict = {\n",
    "      \"X\": X,\n",
    "      'trace_type': trace_type,\n",
    "      \"path_ep_distance_km\": path_ep_distance_km,\n",
    "      \"path_hyp_distance_km\": path_hyp_distance_km,\n",
    "    }\n",
    "    return state_dict\n",
    "\n",
    "def get_loader():\n",
    "  dataset_name = 'InstanceCountsCombined'\n",
    "  task = '1'\n",
    "  num_samples_per_trace_type = 1000\n",
    "\n",
    "  dataset = sbd.__getattribute__(dataset_name)(\n",
    "    sampling_rate=100,\n",
    "    component_order=\"ZNE\",\n",
    "    dimension_order=\"NCW\",\n",
    "    missing_component=\"copy\",\n",
    "    cache=None\n",
    "  )\n",
    "  metadata_df = dataset.metadata\n",
    "\n",
    "  eval_set = 'dev'\n",
    "  split = dataset.get_split(eval_set)\n",
    "\n",
    "  # task_csv = f'/home/liu0003/Desktop/projects/seisLM/data/targets/{dataset_name}/task{task}.csv'\n",
    "  task_csv = project_path.gitdir() + f'/data/targets/{dataset_name}/task{task}.csv'\n",
    "  task_targets = pd.read_csv(task_csv)\n",
    "  task_targets = task_targets[task_targets[\"trace_split\"] == eval_set]\n",
    "\n",
    "\n",
    "  eq_targets = task_targets[task_targets['trace_type'] == 'earthquake'].head(num_samples_per_trace_type)\n",
    "  noise_targets = task_targets[task_targets['trace_type'] == 'noise'].head(num_samples_per_trace_type)\n",
    "\n",
    "  task_targets = pd.concat([eq_targets, noise_targets])\n",
    "\n",
    "  generator = MetaDataKeepingSteeredGenerator(split, task_targets)\n",
    "  generator.add_augmentations(\n",
    "    [\n",
    "      sbg.SteeredWindow(windowlen=3001, strategy=\"pad\"),\n",
    "      sbg.ChangeDtype(np.float32),\n",
    "      sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"std\"),\n",
    "    ]\n",
    "  )\n",
    "  batch_size  = 10\n",
    "  num_workers = 2\n",
    "  loader = DataLoader(\n",
    "    generator, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "  )\n",
    "  return loader\n",
    "\n",
    "\n",
    "loader = get_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liu0003/miniconda3/envs/seisbench/lib/python3.9/site-packages/lightning/pytorch/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.4.0, which is newer than your current Lightning version: v2.2.5\n",
      "/home/liu0003/miniconda3/envs/seisbench/lib/python3.9/site-packages/lightning/pytorch/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.4.0, which is newer than your current Lightning version: v2.2.5\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_collections = {}\n",
    "\n",
    "for model_type in ['pretrained', 'random_init']:\n",
    "\n",
    "  model = LitMultiDimWav2Vec2.load_from_checkpoint(\n",
    "    # '/home/liu0003/Desktop/projects/seisLM/results/models/pretrained_seisLM/pretrain_config_layernorm_std_small_batch_6_datasets_42__2024-08-14-09h-06m-17s/checkpoints/epoch=33-step=893792.ckpt',\n",
    "    project_path.gitdir() + \\\n",
    "      # '/results/models/pretrained_seisLM/pretrain_config_std_norm_single_ax_8_datasets_sample_pick_false_42__2024-08-31-18h-41m-44s/checkpoints/epoch=35-step=1082700.ckpt',\n",
    "      \"/results/models/pretrained_seisLM/pretrain_config_std_norm_single_ax_8_datasets_32bit_scaleup_samp_false_42__2024-09-01-23h-26m-07s/checkpoints/epoch=36-step=649091.ckpt\"\n",
    "  ).model\n",
    "\n",
    "  if model_type == 'random_init':\n",
    "    model = MultiDimWav2Vec2ForPreTraining(model.config)\n",
    "\n",
    "  model = model.to(device)\n",
    "  model = model.eval()\n",
    "  model_collections[model_type] = model\n",
    "  del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]2024-09-09 11:24:23,745 | seisbench | WARNING | Traces can not uniformly be identified using name. \"get_idx_from_trace_name\" will return only one possible matching trace.\n",
      "WARNING:seisbench:Traces can not uniformly be identified using name. \"get_idx_from_trace_name\" will return only one possible matching trace.\n",
      "2024-09-09 11:24:23,803 | seisbench | WARNING | Traces can not uniformly be identified using name. \"get_idx_from_trace_name\" will return only one possible matching trace.\n",
      "WARNING:seisbench:Traces can not uniformly be identified using name. \"get_idx_from_trace_name\" will return only one possible matching trace.\n",
      "100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n",
      "100%|██████████| 14/14 [01:17<00:00,  5.53s/it]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]2024-09-09 11:26:18,025 | seisbench | WARNING | Traces can not uniformly be identified using name. \"get_idx_from_trace_name\" will return only one possible matching trace.\n",
      "WARNING:seisbench:Traces can not uniformly be identified using name. \"get_idx_from_trace_name\" will return only one possible matching trace.\n",
      "2024-09-09 11:26:18,057 | seisbench | WARNING | Traces can not uniformly be identified using name. \"get_idx_from_trace_name\" will return only one possible matching trace.\n",
      "WARNING:seisbench:Traces can not uniformly be identified using name. \"get_idx_from_trace_name\" will return only one possible matching trace.\n",
      "100%|██████████| 200/200 [00:36<00:00,  5.53it/s]\n",
      "100%|██████████| 14/14 [01:09<00:00,  4.97s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings_of_models = {}\n",
    "\n",
    "for model_type, model in model_collections.items():\n",
    "  batch_input_dict = defaultdict(list)\n",
    "  batch_features_dict = defaultdict(list)\n",
    "\n",
    "  for batch in tqdm.tqdm(loader):\n",
    "    for key, value in batch.items():\n",
    "      batch_input_dict[key].append(value)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      input_values = batch['X']\n",
    "      wav2vec2_output = model.wav2vec2(\n",
    "        input_values=input_values.cuda(),\n",
    "        output_hidden_states=True,\n",
    "      )\n",
    "\n",
    "    batch_features_dict['conv_features'].append(\n",
    "      wav2vec2_output.extract_features.mean(axis=1)\n",
    "    )\n",
    "\n",
    "    for hidden_states_layer_idx, hidden_states in enumerate(wav2vec2_output.hidden_states):\n",
    "      batch_features_dict[f'hidden_states_{hidden_states_layer_idx}'].append(\n",
    "        hidden_states.mean(axis=1)\n",
    "      )\n",
    "\n",
    "  all_features_dict = defaultdict(list)\n",
    "  all_input_values = defaultdict(list)\n",
    "\n",
    "  for key, value in batch_features_dict.items():\n",
    "    concat_features = torch.concatenate(value, axis=0).cpu().numpy()\n",
    "    all_features_dict[key] = concat_features\n",
    "\n",
    "  for key, value in batch_input_dict.items():\n",
    "    if isinstance(value[0], torch.Tensor):\n",
    "      concat_values = torch.cat(value, axis=0).cpu().numpy()\n",
    "    elif isinstance(value[0], np.ndarray) or isinstance(value[0], list):\n",
    "      concat_values = np.concatenate(value, axis=0)\n",
    "    else:\n",
    "      raise ValueError\n",
    "    all_input_values[key] = concat_values\n",
    "\n",
    "\n",
    "  embedding_dict = defaultdict(list)\n",
    "\n",
    "  for key, value in tqdm.tqdm(all_features_dict.items()):\n",
    "    # pca = PCA(n_components=2)\n",
    "    # embedding_dict[key] = pca.fit_transform(value)\n",
    "\n",
    "    tsne = TSNE(\n",
    "      n_components=2,\n",
    "      max_iter=500,\n",
    "      n_iter_without_progress=150,\n",
    "      n_jobs=2,\n",
    "      random_state=0,\n",
    "    )\n",
    "\n",
    "    embedding = tsne.fit_transform(value)\n",
    "    embedding_dict[key] = embedding\n",
    "\n",
    "  embeddings_of_models[model_type] = embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    'earthquake': \"#9e0142\",\n",
    "    'noise': \"#91bfdb\"\n",
    "}\n",
    "\n",
    "colors = [color_map[a] for a in all_input_values['trace_type'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from dash import Dash, dcc, html, Input, Output, no_update, callback\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.manifold import TSNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trace_types = all_input_values['trace_type']\n",
    "embedding = embeddings_of_models['pretrained']['hidden_states_12']\n",
    "raw_waveforms = all_input_values['X']\n",
    "\n",
    "\n",
    "def plot_tsne(embedding, raw_waveforms):\n",
    "  # Create 2D scatter plot\n",
    "  fig = go.Figure(data=[go.Scatter(\n",
    "      x=embedding[:, 0],\n",
    "      y=embedding[:, 1],\n",
    "      mode='markers',\n",
    "      marker=dict(\n",
    "          size=5,  # Adjusted marker size for better visibility\n",
    "          color=colors,\n",
    "      )\n",
    "  )])\n",
    "\n",
    "  fig.update_traces(\n",
    "      hoverinfo=\"none\",\n",
    "      hovertemplate=None,\n",
    "  )\n",
    "\n",
    "  extra_space_on_left = 300\n",
    "  # Update layout to make the plot square\n",
    "  fig.update_layout(\n",
    "      width=600+extra_space_on_left,\n",
    "      height=600,\n",
    "      margin=dict(l=extra_space_on_left),  # Add extra space on the left and right\n",
    "      xaxis=dict(scaleanchor=\"y\", scaleratio=1),\n",
    "      yaxis=dict(scaleanchor=\"x\", scaleratio=1)\n",
    "  )\n",
    "\n",
    "  # Dash app layout\n",
    "  app = Dash(__name__)\n",
    "\n",
    "  app.layout = html.Div(\n",
    "      className=\"container\",\n",
    "      children=[\n",
    "          dcc.Graph(id=\"graph-5\", figure=fig, clear_on_unhover=True),\n",
    "          dcc.Tooltip(id=\"graph-tooltip-5\", direction='bottom'),\n",
    "      ],\n",
    "  )\n",
    "\n",
    "  # Callback to display hover data as a plotly figure\n",
    "  @callback(\n",
    "      Output(\"graph-tooltip-5\", \"show\"),\n",
    "      Output(\"graph-tooltip-5\", \"bbox\"),\n",
    "      Output(\"graph-tooltip-5\", \"children\"),\n",
    "      Input(\"graph-5\", \"hoverData\"),\n",
    "  )\n",
    "  def display_hover(hoverData):\n",
    "      if hoverData is None:\n",
    "          return False, no_update, no_update\n",
    "\n",
    "      hover_data = hoverData[\"points\"][0]\n",
    "      bbox = hover_data[\"bbox\"]\n",
    "      num = hover_data[\"pointNumber\"]\n",
    "\n",
    "      # Get the time series data for the hovered point\n",
    "      ts_data = raw_waveforms[num]\n",
    "      num_channels = ts_data.shape[0]\n",
    "      # Create a Plotly figure for the time series data\n",
    "      ts_fig = go.Figure()\n",
    "      for i in range(num_channels):\n",
    "          ts_fig.add_trace(go.Scatter(y=ts_data[i], mode='lines', name=f'Channel {i+1}'))\n",
    "\n",
    "      ts_fig.update_layout(\n",
    "          margin=dict(t=10, b=10, l=10, r=10),\n",
    "          height=200,\n",
    "          template=\"plotly_white\",\n",
    "          # title=f\"Time Series\",\n",
    "          title=f\"Waveform {num} of type {all_trace_types[num]}\",\n",
    "          title_x=0.5,\n",
    "          title_y=0.95\n",
    "      )\n",
    "\n",
    "      children = dcc.Graph(\n",
    "          figure=ts_fig,\n",
    "          config={'displayModeBar': False},\n",
    "          style={\"width\": \"100%\"}\n",
    "      )\n",
    "\n",
    "      return True, bbox, children\n",
    "  app.run(debug=True)\n",
    "\n",
    "  return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fef802f98b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<dash.dash.Dash at 0x7fef6e913a30>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_tsne(\n",
    "  embedding=embeddings_of_models['pretrained']['hidden_states_12'],\n",
    "  raw_waveforms=all_input_values['X']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fef802f9910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<dash.dash.Dash at 0x7fef802f9970>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plot_tsne(\n",
    "  embedding=embeddings_of_models['pretrained']['hidden_states_10'],\n",
    "  raw_waveforms=all_input_values['X']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seisbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
