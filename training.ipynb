{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ml_collections import config_dict\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from transformers import Wav2Vec2Config\n",
    "from seisLM.model.lit_model import LitWav2Vec2\n",
    "from seisLM.data_pipeline import collator\n",
    "import seisbench\n",
    "import seisbench.data as sbd\n",
    "import seisbench.generate as sbg\n",
    "from seisbench.util import worker_seeding\n",
    "\n",
    "# from earthquakeLM.utils import datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liu0003/miniconda3/envs/seisbench/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_or_path = \"patrickvonplaten/wav2vec2-base-v2\"\n",
    "\n",
    "model_config = Wav2Vec2Config.from_pretrained(model_name_or_path)\n",
    "# model_config.conv_dim = [a//8 for a in model_config.conv_dim]\n",
    "# model_config.conv_stride = [a * 2 for a in model_config.conv_stride]\n",
    "# model_config.conv_kernel = [a * 2 for a in model_config.conv_kernel]\n",
    "model_config.num_attention_heads = 8\n",
    "model_config.diversity_loss_weight = 0.15\n",
    "model_config.input_dim = 3\n",
    "\n",
    "\n",
    "training_config = config_dict.ConfigDict()\n",
    "training_config.mask_time_prob = 0.65\n",
    "training_config.mask_time_length = 10\n",
    "training_config.global_batch_size = 4\n",
    "training_config.seed = 42\n",
    "training_config.warmup_frac_step = 0.2\n",
    "training_config.learning_rate = 1e-4\n",
    "training_config.weight_decay = 1e-4\n",
    "training_config.num_train_epochs = 20\n",
    "training_config.adam_beta1 = 0.9\n",
    "training_config.adam_beta2 = 0.999\n",
    "training_config.adam_epsilon = 1e-8\n",
    "training_config.max_gumbel_temperature = 2.0\n",
    "training_config.min_gumbel_temperature = 0.5\n",
    "training_config.log_every_n_steps = 100\n",
    "training_config.logger_project_name = 'seisLM'\n",
    "training_config.num_workers = 1\n",
    "training_config.model_save_dir = \\\n",
    "  '/home/liu0003/Desktop/projects/seisLM/saved_models'\n",
    "training_config.num_train_fraction = 0.8\n",
    "training_config.num_val_fraction = 0.1\n",
    "training_config.num_test_fraction = 0.1\n",
    "training_config.precision = \"32\"\n",
    "training_config.gpu_devices = [0, 1]\n",
    "seed_everything(training_config.seed)\n",
    "\n",
    "\n",
    "model = LitWav2Vec2(model_config, training_config)\n",
    "\n",
    "\n",
    "data = sbd.STEAD()\n",
    "mask = data.metadata[\"trace_category\"] != 'noise'  # Only select events with magnitude above 2.5\n",
    "data.filter(mask)\n",
    "train, dev, test = data.train_dev_test()\n",
    "train_generator = sbg.GenericGenerator(train)\n",
    "val_generator = sbg.GenericGenerator(dev)\n",
    "\n",
    "augmentations = [\n",
    "    sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "]\n",
    "train_generator.add_augmentations(augmentations)\n",
    "val_generator.add_augmentations(augmentations)\n",
    "\n",
    "\n",
    "\n",
    "data_collator = \\\n",
    "  collator.DataCollatorForWav2Vec2PretrainingConcatChannelsNoPadding(\n",
    "      model=model.model,\n",
    "      mask_time_prob=training_config.mask_time_prob,\n",
    "      mask_time_length=training_config.mask_time_length,\n",
    "  )\n",
    "\n",
    "dataloaders = {\n",
    "  'train': DataLoader(\n",
    "    train_generator, batch_size=training_config.global_batch_size, shuffle=True,\n",
    "    num_workers=training_config.num_workers, worker_init_fn=worker_seeding,\n",
    "    collate_fn=data_collator,\n",
    "    ),\n",
    "  'val': DataLoader(\n",
    "    val_generator, batch_size=training_config.global_batch_size, shuffle=False,\n",
    "    num_workers=training_config.num_workers, worker_init_fn=worker_seeding,\n",
    "    collate_fn=data_collator,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "training_config.max_train_steps = training_config.num_train_epochs * len(\n",
    "  dataloaders['train'] )\n",
    "\n",
    "\n",
    "# Training loop\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val/loss',\n",
    "    save_top_k=1,\n",
    "    mode='min',\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "formatted_time = time.strftime(\n",
    "  \"%Y-%m-%d-%Hh-%Mm-%Ss\", time.localtime(time.time())\n",
    ")\n",
    "run_name = f\"{training_config.seed}__{formatted_time}\"\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=training_config.logger_project_name,\n",
    "    save_dir=training_config.model_save_dir,\n",
    "    name=run_name,\n",
    "    id=run_name,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "logger.log_hyperparams(model.hparams)\n",
    "logger.log_hyperparams(training_config.to_dict())\n",
    "\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    profiler='simple',\n",
    "    logger=logger,\n",
    "    log_every_n_steps=training_config.log_every_n_steps,\n",
    "    devices=training_config.gpu_devices,\n",
    "    accelerator='gpu',\n",
    "    strategy='ddp',\n",
    "    max_epochs=training_config.num_train_epochs,\n",
    "    callbacks=[\n",
    "      checkpoint_callback, lr_monitor,\n",
    "    ],\n",
    "    default_root_dir=training_config.model_save_dir,\n",
    "    precision=training_config.precision,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=dataloaders['train'],\n",
    "    val_dataloaders=dataloaders['val']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_length 6000\n",
      "batch_size 4\n",
      "features_shape (4, 18)\n",
      "seq_length 6000\n",
      "batch_size 4\n",
      "features_shape (4, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_values', 'attention_mask', 'mask_time_indices', 'sampled_negative_indices'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(iter(dataloaders['train'])).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 200])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.randn(10, 200)[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seisbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
